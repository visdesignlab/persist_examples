{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "522fcbb3-702c-4ea0-91d9-f3b0e71690fc",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰àᦴ΀࣪ʐ怶䦠挠᱊ࠥ䁁䂖㚥煤晬փ⊪ĸ暂䙠঳ैkᑄᄈ妐ଷᓋ⃩䖻Ṯ溜Φ䐡傠Ǒ団Қ′䈤7ࡣᠠ湐戎Ⴆ寐爤䀥屨攠ʕ㥀ǔÚ䍃㏙䤥ࢂ┩勸惀Ēいཆ༠೥∁∀秸㲅䌠ⶬᛦ䙂ǃɡ殍戰泤ᒁ嬦怭㋉匥穃ᄠ彣჻⴦䉫ぢ睤䄁ⵐۻG䀡曑砑䂱竖ᄂ㜿Ꭽ˹ȩᚱ凁兘㑐Ṣ༩Ẻ䳥⑆憰棨忞⍧攈堽Ī僰὆揖䦲ᡊ⛓౱নఱ姼ᤦΧ您別൧儸晋Ǣ熘繀䉁硨K塊়ṹᜰ倳䪂ⵦ⚈ᒽ᪺ᆬ䀠 "
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebadbe2-4497-401c-9220-017809e835de",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠବɐච䎍倶䊪ᠠ父嬡ᳺ෪ੲࠬ晴ᘦ㍲差Ⱗㅅ)㊤䈽ାƂ刴喋橖㎁混䩟ႠᨰV岸㈔␢⡠䀢焧匠෦భ戰௷㙠̸x䠊䀡᲼䠠洠⺾彡抄䀠㈉㶣㡶ᡈ\\䰩(懄燃㌂㰢ᒌ娾䀶挥㗦ࢢ烡ၕ⬱жㄢ៉䓐͸⮑ŝㄐ䁏你㋲既祸ၛᅀ㢆䰽⫠਀⻚粀幝ඨ࣓叾殪㙡ƨ◓ᰢ寘奇Ⴌ䦦糂礒৉ᱥ䩃༥ס扦᤭ԓ噻ҩᆠ剋࣡ସ䂡▥撰じ㸨䅃䢴മ䂁ᣌ㬫䈁碢➫怢崢悩欂䥑央Ⴧ掴≺䩬槔ဨ搠 "
   },
   "source": [
    "In this notebook you will work with the data for [avalanches in Utah](https://utahavalanchecenter.org/avalanches). The data was sourced from the [Utah Avalanche Center](https://utahavalanchecenter.org/).\n",
    "\n",
    "We will ask you to perform three basic data analysis tasks. Please follow the instructions and note your findings and/or any issues you face in markdown.\n",
    "\n",
    "<font color=\"red\">In this notebook, you will be using pandas to perform the tasks. Pandas is already installed and enabled in this notebook environment. You are free to use any library like _matplotlib_, _seaborn_, _altair_, etc. to create your visualizations. These libraries are installed as well. You can use the internet to get help with the syntax python or how to use a particular library.</font>\n",
    "\n",
    "You can add new code and markdown cells as required to complete the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337796b-21e8-4c8c-bbbd-3076a775d03b",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ಀଠ䰢ᧆƸѐୢ佌Ǒୠܬ䯈ৠᶠ㌱晓勦⤐㍕ተ¶⡨⇳㌄ᅆ⥦亱⍶癭ᷫ㬗琰͢&恫ٞ碠┨ࠠ⹀窀ǘ憡屢ƚ盤䀫ㄝ⠠乮␠㚠ᝯ⿀煒†ᤔ⢡ɋఴ>☤䀤㎳ᠹ搠噶ء㪯‫ㆢ報ѠҀ䡊嗐䈣ᢦ௲扸ǌ攤罎䢈‷柇檌Ⴡⰰ渁ၘ⍬ۊ怩瀠㩎屰幐ᑎ櫤᡹樏ぅᭀ䅥戬⠸繦᪥䦴⓪㇁声ಙ瘡ㄡᬊ৤簨䲡ʤ硶痘䂱䂲䖰漩ౠ罅䌀䥐ᱞ౥၈⩍སヸืϣ瀤伪%㰙Ń厎䝨壙᜸卉ӕᢵ冲䍀  "
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd # Load pandas for data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81aecd-eebf-4624-b9e2-3a864c474c1d",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ҁ̡䘠烠嘢త〫‥侴ᓬᛞ拐ৡ䚂ద抭婈ހڅྯ䌲⠠䭈⑁槑焳Ⴥ⩦仃㍶๽㰥Ҩǁ#㟢䌰橠ኤРᜰ͐üメ湁˛㾄ָ̠憴)挄䀦栢琭ٮ㍄ᨡ䌤ᾣㆢ䀣擠䢤㘦Sᥧᡠ戂怡ᠬÖᠻ㹈䐿ة׉妨⃓ࢱ̴㖠᫲徤ฏѤƜڣ回㸦ۡ৵ण䃔戊㘠传ϊ緯挡䘌污䕽庮粓㈨ɪⷠ搃猄ᦨ洘㳌ᤪ̪౦繶ሱ澂䘣⁑Ҝഭ炍孉ृÅ⭱䤾ᢠ䆋෭ኀ㠢Ү≱呺Ấ惑汮ᮯ戩䊏̠˙Ɂ⧽憳㈒ṉⅱਊ⥋⃆瑀⣨  "
   },
   "source": [
    "## Data Description\n",
    "\n",
    "The table below describes the different columns in the dataset. Each row in the dataset is a reported avalanche with the location, trigger, aspect of the slow. The data spans multiple years starting from 2004 upto 2023.\n",
    "\n",
    "| Column          | Description                                                      |\n",
    "|-----------------|------------------------------------------------------------------|\n",
    "| Date            | This is the date on which the instance of avalanche was recorded |\n",
    "| Region          | Region in Utah where the instance was recorded                   |\n",
    "| Place           | Exact place where the instance was recorded                      |\n",
    "| Trigger         | The cause of the avalanche                                       |\n",
    "| Weak Layer      | Layer of the snow that was weakest and likely the one to fail    |\n",
    "| Depth_inches    |                                                                  |\n",
    "| Width_inches    |                                                                  |\n",
    "| Vertical_inches |                                                                  |\n",
    "| Aspect          | Direction of the slope where the avalanche happened              |\n",
    "| Elevation_feet  |                                                                  |\n",
    "| Coordinates     | Approximate location of the avalanche                            |\n",
    "| Comments 1      | Comments added by the reporter                                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e426c-89a0-4813-8994-65ebba3f3a25",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰໠⬠Ⱓ〨悆æĬ˰ă‹䁮सҀ挩≴倳Ԛ樆⩍璁ࣣ捤䨠ዪन㪌糥擊桒ㆆ槻域℁兀†沨烦ᦰӁĠװ搬W౐ި₏湘အザᥠ¼湨N䣸持㉠Q఩Ⅴ㬸ᐠṬү⋦僃⣐案㲖ᘠ䣠ஃϒᎨ䂨悰㫛ҤݑԴ㇥堣Ⳋ䓡㺨摠៨摖泂ေ氰己ၘ⭬ǎ怩瀠㧎㸜〤㻍䐤己洄ⓖ₡⒅呰Ӕ㬹༾䗢䃣懳⢪⓴ᡒᒤ⏼傖أ礱瑹凩夌㈴䡮䢠挴⊂̥㘯ᙩ䌁Ѳʣ⇱ಆᖡ憐㱞dႨ抄䀪瘪䊇➮◦ᐤ䪸佱䥺╗⇇ᅠ  "
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./avalanches_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc10d2b-9b1e-46f4-9769-b9a0ac0c9e8f",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㌬Ā჻R〶䁃lyٹ⁓f䍐ۢ䧪㈉◔ฅޡ䨲⠠䬱䑁棒瀱Ⴭ⭱妻ݎẜʤ䐡傠ǖ悃РኤРᜰ結üメ浪巟㈠ᣠˬ⃪$熒‣㐡㬚͇⦲༿⸂໡壡‡犀⒂ଠᎭॣ䥡⊃㡹稠嬸ූᑤඦҡ哹䑀妨䤝͕䀺慽䈩瞤∡㼚ƶ嵖᯦悡檩ǣ᪀畖o#䖊⠃ܑ璌⃥⹾䞌᧒Т⺈ᆡ⇳㴑䒤㒌ŭ᯸丈◡戱⃰潅Ԧ秐噑๦磜疶溂⒀ᒪ扖⋦ူⶃ㧄మྡྷშ⨭རㅸ瘭ǅ爘䅐䘆砠址䑂㥨㈼㹯䕈䓵ᒹ憴婊③ᤠ "
   },
   "source": [
    "## Task 1: Cleaning the dataframe\n",
    "\n",
    "In the first task we will perform some basic data cleaning operations to get our dataset ready for further tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec7bca-0c9c-4608-b987-7396eff240f4",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㬠氤〥䌸瀶䀹䁣๲ৠܦᔨҀᣴ䂼䋃‣ᓆ做►䀳ല⠠䭈⑁槑瀱ᝉ⍮冫㭮ẜʦ䒠ǁ#㕀挸晠ኤРᝣၐüムṁǟ㤉䀥䉸攠ʓ㥀ǔÚ⎃஥䤫䒄攭ᇸ惀Ēいᘦᖠೣ䗫⃂変ⱦ{ఽ咼∪⌤䋵汄ჹ䑈冣ᛠඉⵆܔ⍂Þ⍡歹ম悩溩Ǡ媁疖o#䖓瀃ʅ璌⁅溮杲◒Ъ⍁䔶户ࣉⓢ削౐䘰䵥䌂んḸئԢ灐糕൤㧶ⶬ䲱䅲ᗈ撯ౠ惍䈅䥐属ѣ၈⩍སヸ๗௧焤ᄸ䒰Ž䅰䔉燩壥༲刳樲⭮✈咰ᒄ  "
   },
   "source": [
    "### Task 1a: Removing columns not required for the analysis; and fixing column names.\n",
    "\n",
    "When we print the **df** dataframe we see that we have a column called **Comments 1**. It has text comments made for each recorded instance. For our current analysis we are not going to use this column. We will drop this column from the dataframe.\n",
    "\n",
    "We also have four columns: **;Aspect**, **;Region**, **;Trigger**, **;Weak_Layer**, with a `;` character in the column name. We should rename the columns to **Aspect**, **Region**, **Trigger**, **Weak Layer** respectively by removing the leading `;` character.\n",
    "\n",
    "<font color=\"red\">Write code to rename the four columns and drop the one as specified. Assign the variable to a new dataframe called **cols_fixed_df**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15449b-4ead-4e30-b779-dd88a7169454",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰໠⌠䰥〰怶ᨡథ僥ഽ䘈⤃Ц怳䀧᢬͐皆㸌林伲⠠䭈⑁槓狳Ⴥ⍤䆫᭮滝紤䀡傠Ǒ摃߂′䈤7ະᠠ湐懎Ⴇ᫓〸怢扏⨠Ꮓ䤠ව׵樋涬䠠ٽ߀✲晠޳Ł傸⢬穌ਜ਼̥̲䗰˸慌㣢ြᡄዒ扁ݬ↦用ᘠ歲也叄ᨰؕ欖ᨠ晘ཫɋ㱄ܠ榦噸Ŝ.▷㞬ϳ囑Ĳ㣹沐⛨ၑӃਦᖡ䚇㇃ࣰ⢘癊⌮㢱䌬擁捼倬ة礀ᐯ۪墌ሤ䘤䥍ͤ㢂Иᚇቩ䌀в๩⍱㒅ᖡ憐㱞n愩焠ᗿ搩๎ᒫඳ䢘抮䊁ঊ⥓⃄䂣ဠ "
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c28407-80df-4df4-b729-29c387859558",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰໠̠ᰦᣠ⌶瀶䁋f猨˥䬭܎⁣ᇥ勠ፑೳ⫠㌴ተ¶憨⇳㈀ᅁ╶廃ୖ໽㸚焩#℠Ί挠椨EШN㵀〡岁䋼䳓㞋%呡吠➇ሠ᭠௏偔㢹ჱ穸䄆㖬ਠཆɠ倢㡐⣙Ṭ婆㒿‫ㆦ子䑡䲀䠪痈䈽ᢦ࿵慸ǌ◬缮䢈‷濃梈ƻᣑ嘨ᜐ䠼Ệս〤砠ᴷዾᡌފ戴⌇ゖ㊻ၡ抆湈㕕Ꭰ⌨⃄灓⥦墹䚊㙁଺䌣ڀ⡰ᨶ狡汋㫬枨ũࠠ㞥ـ㾪斑Ⓒ฿΀ᑔᴡ䊂塄㪧䐂Ӣᱠ֗礢䏄䵀挄㉅ή⨑㔷౪梔ư  "
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab8f8f24-afd2-424f-ab34-3e3cde723aa3",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ࢀㆪこ<ǐʀ୥崡汤Ɓ䔠⍂⠨撂䂼ì债晶堪慯掩ᐠ▴ሰ璹㤨䮲减ⓥ䢧᜾㺣䉠ð䀡壅冨㕀ॢȠ௞䠸ᢀ眰䅽忖䀢晐樠Ԃ牠ΈƔڦ❓ሠƠ暬ॡ声Ȅ恨䙜⬮ಬ俨⫣䞐డ㙐᬴⣔䰲ճ㌰䊆၂۔欠㖹┰᧶༨̘ඛฌ琻ɋ㉄ܠ榡哸Ŝ.ؗ⾬ള勑̵㯺ᱱ曨ဩᒡᾪ३⁂惡৒ј⪖ᩋࢶ䥣䍢ᇃ⢀☾ԣ䖎㑝䳓ⳄⓀ᪱ĦҐ戤׌㝔䆦成扉ڠ凈㨣ೣㅘ湏Bࡤ䒠ଈତޗ٩䟨㣜㥨◈ᩲ㭡⟢䀠 "
   },
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ded8ee-7828-494d-afeb-8f5b5b5595f1",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰à⬠氤瀹䂃¦¸˰ҁ①าÐɐ໦䓊禳Ӧ攆⩧琫樁拄䨠ዪन㪌糥效桖㖎槻域℁兀†沤挹䠤傡%梄ؠᮬᢛ䑁圌ḀÐ乒䀡ᵼ䠠洠⺱壹溄䅢ᨀ䈩㙐⠠㲸ब佄⍦儂ト桦{్䂼∠⌤䉶汄ၹ䑨凝۠ඊ⡂ڗ䉂Þ⍾捠ೠ䞫づ㕤䄀൐櫻G䀡擑琑䈂㫶ဲ㜧Ꭱ˹ȥᆲ冲椒咃ᨼᐱᒶ䭢䇡Ᏹユ僌䘼ᚦᩐ挬ദ䌜๵䎃ᅄ〴䦈᥃䌰ࡃ㏙㉬ᜨ⊰ᒊ຤惐氮ண成ɁѦቄwၤቘ㲒㙑⏤咤窤䫳䧚ᕄй  "
   },
   "source": [
    "### Task 2a: Removing outliers in the records for Elevation and Depth\n",
    "\n",
    "Below we have an interactive scatterplot with `Elevation` on the X-axis and `Vertical`. We see that there are some outlier's in the data here, possibly incorrect data input while entering the avalanche instance. We should remove these outlier before we proceed with the analysis.\n",
    "\n",
    "<font color=\"red\">The scatterplot below is a scatterplot in seaborn.</font>\n",
    "\n",
    "<font color=\"red\">Remove the outliers you see in the plots, and print the final plot.</font>\n",
    "\n",
    "<font color=\"red\">Assign the cleaned dataframe to a variable called **cleaned_df**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c94f8c-46b7-4050-9c92-0d8edcf2176a",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰àㆠ氦ムํ‶䀹䂖lᤨˠᖠ✱¬殴⁣୑ᥣ⵸㏷剪2攩њ㙜Ʉᓉ橔ᆆ桳䵗⾞䇢†浘戼䠤傡%戠映ᮬ᡻䑁ᚍ沣‡㔸㔠ʖ㥀ǔÚͣ⏉䤥䘯㍸惀ĒいCၴ佧敂掲Ӑؠ嬸㗛Ѥ໦Ң坺䑁ᦨࢣጵ䀺晾搪疧䈡㸦㻆煛ഺ悦沩Ǣ᪀㗶o#䦍氃͢痌Ⅴ⹾ޖ᧒м⥈慥厳烓ѹ劊ᘭࡣ࡯⏧㏊ᣁᑢ㬫ᒹ㳋۲⑨惩የ㖤䙀⁪斑Ⓒ฿Ɂ䢴ഡ䚂堼ᜧ䐀Ѣឭ\"崢悱朆䣱㥆ᣁ扴㲚䁮榩愰搠 "
   },
   "outputs": [],
   "source": [
    "plot = sns.scatterplot(df, x=\"Elevation_feet\", y=\"Vertical_inches\")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370f561-7a3f-4a65-96b7-2f8575bbf256",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰àᬡ䰤ᯀ嘸ׂ怹䭢Ò煠✡Xᥫ⬡౓⭠ᇕ¹Ⲍ⒴E䨲࢔沙ѩ䠴减⣹䶧㝞ᘢ†桠ù㊑䏾ဩ™+䝨ఠ㜸ヷࡣ䵹堬〡㘷唠ৱ撠۰̊甕盦␴⺧偋ঃʠϩ䂰Ⲉ橚[བྷா⛁㌈ƌザⱁ࠶లॹ㘰䏆უ㪼ଠ㗉⬿槲ന̚疛හཫɋ㱄ܠ榦噸Ŝ.ַ㞬ϳ勑ز㣹泐⛨ၱ㢯ᜪ๮∀戲㊘甒戯ⵇᲮ䈀℗რ慸㐴ʥ屜᭒曗ਂr∤ก憨က妼ॆΣ∐≉Ţ冈سѥ⣘幟ࡃ䐠垟၀㣙ሬ⬻ጃਢ╮悲ᩍႄ  "
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa413fa-c1e8-4c9b-a6c1-d99240948a75",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰࣠✴ƀචآ൐ୠᣠ⭎¸䚀ᶥ<⋵攴≲䦆ᨐ҅䁲䥈kᑄᄈ夒ર囇⣹嗛➎帣ᢤ䀡傠Ǘ熠㥀ॢȠா䠸ᢀ㜰䁾巒•橀樠Ꮃ䤠ව׷核ᱬ䣘紲₞૦Ԡ޳ŀ凐栠晬╍ಲ䖽䂇栢沀團ᄰ㸸ሪ喊Ⴇ♁䐔粶ᦞΎ刺ࠥ簉窺簲ᖢොሧ҉䃵ⰡḠޅ毗䘤䗾墥୚渍磆搰㣄䆯䌭䊣ᎄ䢩妈䪑䴹ҩ䋫◂რ⢒ઉ⃁⽌囦媍ኘ垤䢠䍤⒂Йᘷ੡䄀҂Ქ⃱琿啡憐㲞ၯ䌨焠ᗿ搫໎㒫ல熪Ņ⎃ऺᥛ⃄ᅠ  "
   },
   "source": [
    "### Task 2b: Filter out old data\n",
    "\n",
    "Below we have an barchart with data aggregated by the year. We see the `Year` on the X-axis and `number of records for the year` on y-axis. For the two years before 2010, we have very few records. We will remove these records from our dataset.\n",
    "\n",
    "<font color=\"red\">Filter out the data points as instructed using pandas.</font>\n",
    "\n",
    "<font color=\"red\">Assign the new dataframe to a variable called **post_2010_df** and plot it the same as the given barchart</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40106aef-2b86-42eb-b384-72b0a6166dfa",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ӡㆠ䘤瀥䀮ȥ倮怰恓ྂ㩳ᴂ壢䛈祥䁶㨶㏩ᐠ▴ሰ瓹碩䥱叀擥䶧㝾猜†桠û䢁䇶ဩ™+䭨ఠ㜸シࡢ䱺孠ƄᏊ3廲V䀷ⷃ嗔᥀9媈㾒㦬ਠཆɠɐø墘剨䚉ᒭᤷ䇦栢沁朄䄰㤸ሪ庄Ⴅ♃ϔᢆᦙ߫場ࠥ箉窺Ԋ猤᭨␮ࣳǏᠢ㰠ຫ✯఺௕ㄤ႒壻䢭䡀ᅑᨮªʣ䝁⌲ጐピⰬ䤦£䔓A⃀ᢖẮ←嘵嶉㧤रࢇҬ‿೨玩᡼Ⴂⁱ呺и勑䒖Ꭳ懀簬cࠡ⹞ᾰ犐┈璫ல燬㹐䵰䨊ᥖਠ "
   },
   "outputs": [],
   "source": [
    "sns.histplot(x=pd.to_datetime(df[\"Date\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92b8a9-c3a8-4a57-be3b-c9cdc977092c",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ⬠沈֭⠸恍ff9昽䁮ۦ࠰汬നڀপ㈏䣹厠㬦ተ¶⡨⇱㌀ᅁ╶庳ୖ⹜簧ଭࠣ℠Έ橦औ䁅ШNႦ〡岁䏼ℭ㞁摞+㢱䨠Ԋ牠Έƕ٦枓቙ჿਸ旑䅠Ȅ恨戬പᎭె䝁净儬Ö᡻⌸䐱䘩׍宨⇓ࡱ䍲ච᫲壬จ䙤Ɲڣ圖⍞ᛡ৽ण䃔戋㘠传ϊ揿振䘌汣䓼㹮䘫㈨ቺ⩯↧ᄨXഉ⠅ㅖࢢ侸⇄僡ಖࡢҁ氣С宍劄倶䢡⍤㲂̤㚗٩䄀硂಩⍰琦ᦪ悑屾ᾨႨ㺜*瘪䋇޶⋤ᓘ犠䭳঺᥇⏰ᅠ  "
   },
   "source": [
    "## Task 3\n",
    "\n",
    "We will use the new dataset for avalanches post 2010 to further analyse relationship between phases of the avalanche season and other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0e041-31f7-464c-bb6e-c853fbc0c077",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "### Task 3: Categorize data in phases\n",
    "\n",
    "Out data is missing the data for phases of the season! We have to add a new column to the dataset called `Avalanche Season Phase`. The new column column will have three values: `Start`, `Middle`, `End`. You have to categorize the data into one of the columns depending on the month. Refer to the following order for assignment:\n",
    "- **Dec - Feb** -> `Start`\n",
    "- **Mar - May** -> `Middle`\n",
    "- **June - Nov** -> `End`\n",
    "\n",
    "<font color=\"red\">The barchart below is a barchart in seaborn.</font>\n",
    "\n",
    "<font color=\"red\">Assign categories to different subsets of the data using pandas.</font>\n",
    "\n",
    "<font color=\"red\">Assign the new dataframe to a variable called **season_phase_df** and plot it the same as the barchart earlier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72500be-3a05-464e-9b61-c16706a9c2c2",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰怶Xْ䂦⠩䁍ጡ᱄΄᫊¬͒ཧ൤䧦,糃刚滁አӔౢګᜡㅒ䫵画᫗㌃柠␠ന;㌸嵨‡ᑀ‡㮈䠦熦֜ⴅ痬6懚倡ḍဦ栢璕㩐㭃∧ݳః䃑䅠Ȅ恨f㤩=䅠ք旳爓⥚{థ䜨∣䌤䁴ⶤ၉䑀亭᳠ං⧦碔̢Þᴾ䍠೧ডち㜤䄁畐⪫G䀡棞ទ䊀㭶ტދථɄ♂ł䂐琑梔哢⪆㔡䪧ᑁსᤨ㢷ȸᤧը⛶૽㙐扐ᱱ〺慣࠻杒ᰲػϡࣄԪ䗀ᡬଣ畳㣜㼪г∠⯗䰄ᷤ䤺ፄ搄ᱲ侫ㅘ≦䩩&† "
   },
   "outputs": [],
   "source": [
    "months = pd.to_datetime(df[\"Date\"]).dt.month_name()\n",
    "plot = sns.histplot(x=pd.to_datetime(df[\"Date\"]).dt.month, discrete=True)\n",
    "plot.set_xticks(ticks=range(months.shape[0]), labels=months)\n",
    "plot"
   ]
  }
 ],
 "metadata": {
  "__CATEGORIES_META__": "{\"categories\":{\"Avlanche Season Phase\":{\"name\":\"Avlanche Season Phase\",\"options\":{\"_None\":{\"name\":\"None\"},\"Start\":{\"name\":\"Start\"},\"Middle\":{\"name\":\"Middle\"},\"End\":{\"name\":\"End\"}}}},\"activeCategoryName\":\"Avlanche Season Phase\"}",
  "__CATEGORIES__": "{\"categories\":{\"Avalanche Season Phase\":{\"name\":\"Avalanche Season Phase\",\"options\":{\"_None\":{\"name\":\"None\"},\"Start\":{\"name\":\"Start\"},\"Middle\":{\"name\":\"Middle\"},\"End\":{\"name\":\"End\"}}}},\"activeCategoryName\":\"Avalanche Season Phase\"}",
  "__persist_nb_uuid__": "2bccb628-9e31-4bb8-bddc-dfaa8aff51a3",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
