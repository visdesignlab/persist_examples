{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "522fcbb3-702c-4ea0-91d9-f3b0e71690fc",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰àᦴ΀࣪ʐ怶䦠挠᱊ࠥ䁁䂖㚥煤晬փ⊪ĸ暂䙠঳ैkᑄᄈ妐ଷᓋ⃩䖻Ṯ溜Φ䐡傠Ǒ団Қ′䈤7ࡣᠠ湐戎Ⴆ寐爤䀥屨攠ʕ㥀ǔÚ䍃㏙䤥ࢂ┩勸惀Ēいཆ༠೥∁∀秸㲅䌠ⶬᛦ䙂ǃɡ殍戰泤ᒁ嬦怭㋉匥穃ᄠ彣჻⴦䉫ぢ睤䄁ⵐۻG䀡曑砑䂱竖ᄂ㜿Ꭽ˹ȩᚱ凁兘㑐Ṣ༩Ẻ䳥⑆憰棨忞⍧攈堽Ī僰὆揖䦲ᡊ⛓౱নఱ姼ᤦΧ您別൧儸晋Ǣ熘繀䉁硨K塊়ṹᜰ倳䪂ⵦ⚈ᒽ᪺ᆬ䀠 "
   },
   "source": [
    "# Analyzing Utah Avalanche Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf1206-e99f-45b6-a92b-d971a2a8eb19",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠܠ昢〽䂆౐׀ৣfL⍉ျ⥒⠡䒙¬ᧇ峕搢ಒ嫒┠অҤᵖ㹢晴㘉ᦳㄍ毿䡨墠ᨰV䆼ガ搢⡠䀢焨㌠෦ౝ戰殖๠ᠠ塩ೀn坄V䀷⢄㚗᥂夬ು䅻ఴ>☤䝃傳狱⊔㳜ੁ䀶挫㐷ࢢӡჵ嬩іㄪᢉ懐ͻ䬥䇽ࣨ䁏僿峱䐰㋸ᇻ兀㡆䱍㛠਀ⲛ粀೽疨һ䟩桁㙡Ũ昙ˢ䧮ᄪᆽ䥢ᅅᄁẩ㱸౮ᐶޣ先ఽЃⵖᥒ⌥▶懜ᩑƢ᭛䭄憐ɑ٦⦈䙓ǂ炘㸠䱅࢜ؠଌથ䜯๡䙉夊᜶僑汢㭢☈₁䠠 "
   },
   "source": [
    "**Participant ID:**  \n",
    "**Date / Time:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac0d48-2820-4532-bfd2-adf6533d7a2d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome to our data analysis study. For this part of the study, you'll be working with a dataset sourced from the [Utah Avalanche Center](https://utahavalanchecenter.org/). The data provides insights into [avalanche occurrences](https://utahavalanchecenter.org/avalanches) in Utah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68491102-96aa-4701-8134-d998c80ae04b",
   "metadata": {},
   "source": [
    "- You will use an extension called PersIst to complete **data cleanup and manipulation** tasks. \n",
    "- To familiarize yourself with its functionalities, please refer to the provided [tutorial notebook](../tutorial.ipynb).\n",
    "- Interactive charts and tables have been pre-created for your convenience. These can be directly utilized by running the corresponding cells.\n",
    "- Focus on leveraging the interactive capabilities of Persist for your analysis.\n",
    "- In some cases, you will be asked to document your findings. Please do this in writing in a markdwon cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5d524-883a-460b-8023-2c6aab29570f",
   "metadata": {},
   "source": [
    "## Tasks Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebadbe2-4497-401c-9220-017809e835de",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠବɐච䎍倶䊪ᠠ父嬡ᳺ෪ੲࠬ晴ᘦ㍲差Ⱗㅅ)㊤䈽ାƂ刴喋橖㎁混䩟ႠᨰV岸㈔␢⡠䀢焧匠෦భ戰௷㙠̸x䠊䀡᲼䠠洠⺾彡抄䀠㈉㶣㡶ᡈ\\䰩(懄燃㌂㰢ᒌ娾䀶挥㗦ࢢ烡ၕ⬱жㄢ៉䓐͸⮑ŝㄐ䁏你㋲既祸ၛᅀ㢆䰽⫠਀⻚粀幝ඨ࣓叾殪㙡ƨ◓ᰢ寘奇Ⴌ䦦糂礒৉ᱥ䩃༥ס扦᤭ԓ噻ҩᆠ剋࣡ସ䂡▥撰じ㸨䅃䢴മ䂁ᣌ㬫䈁碢➫怢崢悩欂䥑央Ⴧ掴≺䩬槔ဨ搠 "
   },
   "source": [
    "In this study, you are presented with three fundamental data analysis tasks. Each task is designed to test different aspects of data analysis and manipulation.\n",
    "\n",
    "- Carefully follow the step-by-step instructions provided for each task.\n",
    "- As you work through the tasks, take note of any interesting findings or challenges you encounter, either by speaking your thoughts out loud or taking notes in a markdown cell. This can include observations about the data, any issues encountered, and your overall experience with the task/method.\n",
    "- Feel free to add new code and markdown cells in the notebook as necessary to complete the tasks, but please do attempt the tasks with the PersIst functionality.\n",
    "\n",
    "**Support**\n",
    "- If you require assistance or need further clarification on any of the tasks, please let us know.\n",
    "- If you find yourself stuck on a task and feel that you will not make any progress, you have the option to skip the task.\n",
    "- For tasks that build upon the outputs of previous tasks, skipping a task will affect your ability to proceed. To avoid such problems we will assist you loading a fallback dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9337796b-21e8-4c8c-bbbd-3076a775d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers as h\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "\n",
    "import persist_ext as PR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81aecd-eebf-4624-b9e2-3a864c474c1d",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ҁ̡䘠烠嘢త〫‥侴ᓬᛞ拐ৡ䚂ద抭婈ހڅྯ䌲⠠䭈⑁槑焳Ⴥ⩦仃㍶๽㰥Ҩǁ#㟢䌰橠ኤРᜰ͐üメ湁˛㾄ָ̠憴)挄䀦栢琭ٮ㍄ᨡ䌤ᾣㆢ䀣擠䢤㘦Sᥧᡠ戂怡ᠬÖᠻ㹈䐿ة׉妨⃓ࢱ̴㖠᫲徤ฏѤƜڣ回㸦ۡ৵ण䃔戊㘠传ϊ緯挡䘌污䕽庮粓㈨ɪⷠ搃猄ᦨ洘㳌ᤪ̪౦繶ሱ澂䘣⁑Ҝഭ炍孉ृÅ⭱䤾ᢠ䆋෭ኀ㠢Ү≱呺Ấ惑汮ᮯ戩䊏̠˙Ɂ⧽憳㈒ṉⅱਊ⥋⃆瑀⣨  "
   },
   "source": [
    "## Data Description\n",
    "\n",
    "The table below describes the different columns in the dataset. Each row in the dataset represents a reported avalanche with details on location, trigger, and aspect. The data spans multiple years, starting from 2004 up to 2023.\n",
    "\n",
    "| Column          | Description                                                    |\n",
    "|-----------------|----------------------------------------------------------------|\n",
    "| Date            | Date on which the avalanche was recorded                       |\n",
    "| Region          | Region in Utah where the avalanche occurred                    |\n",
    "| Place           | Exact location where the avalanche was recorded                |\n",
    "| Trigger         | Cause of the avalanche                                         |\n",
    "| Weak Layer      | Layer of snow that was weakest and likely to fail              |\n",
    "| Depth_inches    | Depth of the avalanche in inches                               |\n",
    "| Width_inches    | Width of the avalanche in inches                               |\n",
    "| Vertical_inches | Vertical extend of the avalanche in inches                     |\n",
    "| Aspect          | Direction of the slope where the avalanche occurred            |\n",
    "| Elevation_feet  | Elevation of the avalanche location in feet                    |\n",
    "| Coordinates     | Approximate geographical coordinates of the avalanche location |\n",
    "| Comments 1      | Additional comments provided by the reporter                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0e426c-89a0-4813-8994-65ebba3f3a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>;Region</th>\n",
       "      <th>Place</th>\n",
       "      <th>;Trigger</th>\n",
       "      <th>;Weak Layer</th>\n",
       "      <th>Depth_inches</th>\n",
       "      <th>Width_inches</th>\n",
       "      <th>Vertical_inches</th>\n",
       "      <th>;Aspect</th>\n",
       "      <th>Elevation_feet</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Comments 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/9/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Sunset Peak</td>\n",
       "      <td>Snowboarder</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>14.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>40.577977000000, -111.595817000000</td>\n",
       "      <td>While it was a small avalanche that was I caug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Patsy Marly</td>\n",
       "      <td>Skier</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>North</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>40.592619000000, -111.616099000000</td>\n",
       "      <td>A North facing aspect with an exposed ridge in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Two Dogs</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Facets</td>\n",
       "      <td>36.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>40.599291000000, -111.642315000000</td>\n",
       "      <td>Remotely triggered all the new storm snow (abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Emma Ridges</td>\n",
       "      <td>Skier</td>\n",
       "      <td>New Snow</td>\n",
       "      <td>18.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>40.598313000000, -111.628304000000</td>\n",
       "      <td>Impressive fast powder cloud ran in front of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Sunset Peak</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Facets</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>40.578590000000, -111.595087000000</td>\n",
       "      <td>Three of us toured from Brighton to low saddle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>4/22/2023</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Cardiff Bowl</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>8.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>East</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>40.592721660567, -111.649613218710</td>\n",
       "      <td>We spent the day skiing the southerly-facing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>4/22/2023</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Miller Bowl, East</td>\n",
       "      <td>Snowmobiler</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>18.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>North</td>\n",
       "      <td>8700.0</td>\n",
       "      <td>41.886233332343, -111.645074831510</td>\n",
       "      <td>Not sure about the story here, but we observed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>4/22/2023</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Millville Peak</td>\n",
       "      <td>Snowboarder</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>North</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>41.677564539953, -111.718065248970</td>\n",
       "      <td>Details are a bit limited and we're not sure w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>5/7/2023</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Red Top Mountain</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>West</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>40.546874131921, -111.663880335390</td>\n",
       "      <td>Saw this avalanche around 9.30 AM from the top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>5/9/2023</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Microwave</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>West</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>40.589449603656, -111.613240229200</td>\n",
       "      <td>Intentionally triggered during a ski cut. Ran ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    ;Region              Place     ;Trigger  \\\n",
       "0      11/9/2012  Salt Lake        Sunset Peak  Snowboarder   \n",
       "1     11/11/2012  Salt Lake        Patsy Marly        Skier   \n",
       "2     11/11/2012  Salt Lake           Two Dogs        Skier   \n",
       "3     11/11/2012  Salt Lake        Emma Ridges        Skier   \n",
       "4     11/11/2012  Salt Lake        Sunset Peak        Skier   \n",
       "...          ...        ...                ...          ...   \n",
       "2387   4/22/2023  Salt Lake       Cardiff Bowl      Unknown   \n",
       "2388   4/22/2023      Logan  Miller Bowl, East  Snowmobiler   \n",
       "2389   4/22/2023      Logan     Millville Peak  Snowboarder   \n",
       "2390    5/7/2023  Salt Lake   Red Top Mountain      Natural   \n",
       "2391    5/9/2023  Salt Lake          Microwave        Skier   \n",
       "\n",
       "                      ;Weak Layer Depth_inches  Width_inches  Vertical_inches  \\\n",
       "0     New Snow/Old Snow Interface         14.0         960.0            360.0   \n",
       "1     New Snow/Old Snow Interface         30.0        1200.0           1200.0   \n",
       "2                          Facets         36.0         840.0           5400.0   \n",
       "3                        New Snow         18.0         600.0           6000.0   \n",
       "4                          Facets         42.0       18000.0           9600.0   \n",
       "...                           ...          ...           ...              ...   \n",
       "2387  New Snow/Old Snow Interface          8.0         720.0           1800.0   \n",
       "2388  New Snow/Old Snow Interface         18.0         540.0           4800.0   \n",
       "2389  New Snow/Old Snow Interface         12.0        3600.0           7200.0   \n",
       "2390                      Unknown         72.0        3000.0          12000.0   \n",
       "2391                      Unknown          6.0         300.0           2400.0   \n",
       "\n",
       "        ;Aspect  Elevation_feet                         Coordinates  \\\n",
       "0         North         10400.0  40.577977000000, -111.595817000000   \n",
       "1         North          9700.0  40.592619000000, -111.616099000000   \n",
       "2         North         10200.0  40.599291000000, -111.642315000000   \n",
       "3     Southeast         10200.0  40.598313000000, -111.628304000000   \n",
       "4         North         10400.0  40.578590000000, -111.595087000000   \n",
       "...         ...             ...                                 ...   \n",
       "2387       East          9800.0  40.592721660567, -111.649613218710   \n",
       "2388      North          8700.0  41.886233332343, -111.645074831510   \n",
       "2389      North          8900.0  41.677564539953, -111.718065248970   \n",
       "2390       West         10800.0  40.546874131921, -111.663880335390   \n",
       "2391       West         10000.0  40.589449603656, -111.613240229200   \n",
       "\n",
       "                                             Comments 1  \n",
       "0     While it was a small avalanche that was I caug...  \n",
       "1     A North facing aspect with an exposed ridge in...  \n",
       "2     Remotely triggered all the new storm snow (abo...  \n",
       "3     Impressive fast powder cloud ran in front of t...  \n",
       "4     Three of us toured from Brighton to low saddle...  \n",
       "...                                                 ...  \n",
       "2387  We spent the day skiing the southerly-facing a...  \n",
       "2388  Not sure about the story here, but we observed...  \n",
       "2389  Details are a bit limited and we're not sure w...  \n",
       "2390  Saw this avalanche around 9.30 AM from the top...  \n",
       "2391  Intentionally triggered during a ski cut. Ran ...  \n",
       "\n",
       "[2392 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./avalanches_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc10d2b-9b1e-46f4-9769-b9a0ac0c9e8f",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㌬Ā჻R〶䁃lyٹ⁓f䍐ۢ䧪㈉◔ฅޡ䨲⠠䬱䑁棒瀱Ⴭ⭱妻ݎẜʤ䐡傠ǖ悃РኤРᜰ結üメ浪巟㈠ᣠˬ⃪$熒‣㐡㬚͇⦲༿⸂໡壡‡犀⒂ଠᎭॣ䥡⊃㡹稠嬸ූᑤඦҡ哹䑀妨䤝͕䀺慽䈩瞤∡㼚ƶ嵖᯦悡檩ǣ᪀畖o#䖊⠃ܑ璌⃥⹾䞌᧒Т⺈ᆡ⇳㴑䒤㒌ŭ᯸丈◡戱⃰潅Ԧ秐噑๦磜疶溂⒀ᒪ扖⋦ူⶃ㧄మྡྷშ⨭རㅸ瘭ǅ爘䅐䘆砠址䑂㥨㈼㹯䕈䓵ᒹ憴婊③ᤠ "
   },
   "source": [
    "# Task 1: Refining Columns and Preparing Data\n",
    "\n",
    "In the first task we will perform some basic data cleaning operations to get our dataset ready for further tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934b219-dd97-4e3e-9aa9-0dd7a9d62ad5",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㬠氤〥䌸瀶䀹䁣๲ৠܦᔨҀᣴ䂼䋃‣ᓆ做►䀳ല⠠䭈⑁槑瀱ᝉ⍮冫㭮ẜʦ䒠ǁ#㕀挸晠ኤРᝣၐüムṁǟ㤉䀥䉸攠ʓ㥀ǔÚ⎃஥䤫䒄攭ᇸ惀Ēいᘦᖠೣ䗫⃂変ⱦ{ఽ咼∪⌤䋵汄ჹ䑈冣ᛠඉⵆܔ⍂Þ⍡歹ম悩溩Ǡ媁疖o#䖓瀃ʅ璌⁅溮杲◒Ъ⍁䔶户ࣉⓢ削౐䘰䵥䌂んḸئԢ灐糕൤㧶ⶬ䲱䅲ᗈ撯ౠ惍䈅䥐属ѣ၈⩍སヸ๗௧焤ᄸ䒰Ž䅰䔉燩壥༲刳樲⭮✈咰ᒄ  "
   },
   "source": [
    "### **Task 1a: Remove Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b531d4-2e3a-4e9a-b92a-39aebfc3deb6",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㬠氤〥䌸瀶䀹䁣๲ৠܦᔨҀᣴ䂼䋃‣ᓆ做►䀳ല⠠䭈⑁槑瀱ᝉ⍮冫㭮ẜʦ䒠ǁ#㕀挸晠ኤРᝣၐüムṁǟ㤉䀥䉸攠ʓ㥀ǔÚ⎃஥䤫䒄攭ᇸ惀Ēいᘦᖠೣ䗫⃂変ⱦ{ఽ咼∪⌤䋵汄ჹ䑈冣ᛠඉⵆܔ⍂Þ⍡歹ম悩溩Ǡ媁疖o#䖓瀃ʅ璌⁅溮杲◒Ъ⍁䔶户ࣉⓢ削౐䘰䵥䌂んḸئԢ灐糕൤㧶ⶬ䲱䅲ᗈ撯ౠ惍䈅䥐属ѣ၈⩍སヸ๗௧焤ᄸ䒰Ž䅰䔉燩壥༲刳樲⭮✈咰ᒄ  "
   },
   "source": [
    "Remove certain columns to streamline the dataset for further analysis.\n",
    "- **_Comments 1:_** Contains textual comments not crucial for quantitative analysis.\n",
    "- **_Coordinates:_** Detailed location data not needed for the current scope of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9ad2a-ab09-4288-b8fa-2852bcddda1a",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Column Removal:**\n",
    "\t- Use the interactive table feature in PersIst to remove the specified columns.\n",
    "2. **Generate dataframe:**\n",
    "\t- Assign the modified dataframe to variable `df_task_1a`\n",
    "3. **Show Output:**\n",
    "\t- Print the head of `df_task_1a` to show the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e333ff3-cb24-430b-a332-733b41570ba4",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "ᯡࠣ䅬Ԁ朤壠ᜣ琢〹夢゠⹰〮⁁䁻қ䚾ኊ㇠നСࠩ瀮晼Ƭ穅5愠៤⠠ ",
    "__has_persist_output": true,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9f44e82f3943e9b87d97b32479c0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PersistWidget(data_values=[{'__id_column': '1', 'Date': 1352419200000, ';Region': 'Salt Lake', 'Place': 'Sunse…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR.PersistTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefea2d-3f35-4ab7-aca3-453e28b34efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c62d50-9c88-4ed9-8c97-e552a6e4c620",
   "metadata": {},
   "source": [
    "### **Task 1b: Fix Column Names**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f8f24-afd2-424f-ab34-3e3cde723aa3",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ࢀㆪこ<ǐʀ୥崡汤Ɓ䔠⍂⠨撂䂼ì债晶堪慯掩ᐠ▴ሰ璹㤨䮲减ⓥ䢧᜾㺣䉠ð䀡壅冨㕀ॢȠ௞䠸ᢀ眰䅽忖䀢晐樠Ԃ牠ΈƔڦ❓ሠƠ暬ॡ声Ȅ恨䙜⬮ಬ俨⫣䞐డ㙐᬴⣔䰲ճ㌰䊆၂۔欠㖹┰᧶༨̘ඛฌ琻ɋ㉄ܠ榡哸Ŝ.ؗ⾬ള勑̵㯺ᱱ曨ဩᒡᾪ३⁂惡৒ј⪖ᩋࢶ䥣䍢ᇃ⢀☾ԣ䖎㑝䳓ⳄⓀ᪱ĦҐ戤׌㝔䆦成扉ڠ凈㨣ೣㅘ湏Bࡤ䒠ଈତޗ٩䟨㣜㥨◈ᩲ㭡⟢䀠 "
   },
   "source": [
    "Next, please fix column names to ensure consistency and clarity. \n",
    "\n",
    "It looks like something went wrong when reading the file and some column headers start with a `;`. Please remove the semicolon. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4d5c5-9383-4857-beae-0cfa6ba466f2",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Rename Columns:**\n",
    "    - Use the interactive  table in Persist to correct the column names by removing the leading `;` from their names:\n",
    "        - _;Aspect_ → _Aspect_\n",
    "        - _;Region_ → _Region_\n",
    "        - _;Trigger_ → _Trigger_\n",
    "        - _;Weak Layer_ → _Weak Layer_\n",
    "2. **Generate dataframe:**\n",
    "    - Assign the revised dataframe to the variable `df_task_1b`.\n",
    "3. **Show Output:**\n",
    "    - Display the head of `df_task_1b` to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74dd265-2437-40e4-8673-be7ea1d079b3",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.PersistTable(df_task_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c41e8-53fe-40c1-b827-fd9b6813073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875e7fc-ec40-4241-aa94-87b31e59944f",
   "metadata": {},
   "source": [
    "## **Task 1c: Correcting Data Type of 'Depth_inches'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7eebda-1b60-4bff-89d3-a5548a601b49",
   "metadata": {},
   "source": [
    "There is a data type issue in the `Depth_inches` column of our dataframe. This column is incorrectly formatted as an object (string) due to the presence of the inches symbol `\"`.\n",
    "\n",
    "Remove any inches symbols `\"` from the `Depth_inches` column and convert it to a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bff61-9a8d-4114-97f3-4f6d0cd0e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23913ac-ea3c-4ca1-8ac3-07d3026ca76e",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ↺΀Ơ瘢ᠢᠫ‵䁇ፉ䐢怣侽振ၑ䶃᪰঵䂆⹉多䪲┠অҤᴶṂ㊵嘊᭓ㄅ毠㒰䣑Tဠ㚉҃೨ɰ䂠̂҆;䘸Ϥၗ眼䋐Ð䬹†于␠㚠ᝨ沂烒⎁൸憈㬸ᐠṬү䓧Ⴠ椓ᣘ⌚ᆠᛦކ䜱ǁ䅀㖖नຂᩈ桫〦塵偢㶱⢠⾱䂅埦䖃塀㪂ₐ暸ᵽ䀳怠煼砤慸㴻ࠩ㯏姭ঌ䄢䣫䧙㱈刱ㄿᬦ䩫⏃㌱楫磤ⰴຣα晼ਫ䎁㺕䮃Ⴤご䖂᥂挰ы゙㈬ܠ₰ᑊІ僑汮ޯ戩䉱៪怡⹁ᡤ甑擸抯॰ᡬᅓ╄璚╄㈠ "
   },
   "source": [
    "#### **Instructions**\n",
    "1. **Identify Entries with Inches Symbol:**\n",
    "    - Use the interactive table in Persist to look for rows with `\"` in `Depth_inches` column\n",
    "2. **Edit and Correct Entries:**\n",
    "    - Edit the cells to remove the inches symbol from these entries. (e.g. `15\"` → `15`) \n",
    "3. **Convert Data Type:**\n",
    "    - Change the data type of the `Depth_inches` column from string to float.\n",
    "4. **Generate Dataframe:**\n",
    "    - Assign the modified dataframe to a variable `df_task_1c`.\n",
    "5. **Show Output:**\n",
    "    - Display the dtypes of `df_task_1c` to verify the data type correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9b796-3aa5-4181-bf91-fa8ba7e33c20",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "ᯢ粠 ",
    "__has_persist_output": true,
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ӡ✡ء〨曌ހ୥Vภ㢭恑䝂㣦Ⓖ͐㔥᭸࣪抩ᐠ▴ሰ瓸礨䮲嗏⣹䨻➎帢䈠桠ø㉓械ӁĠפᝬW౐⮨⃮⽹ǀƂ៊3䇩-倥欉甌ユ䒖⺭CƄ性䦡ᄙ⒈Ⲫᙚഽ䀪故栢沀ᘸ愰ظሢ冂Ⴃ♂䎔㤆०࿣尲ࠥ笈稺఺֢׌ሧ߉䅴ⰡḠݥ玷䘦䇺墡ਜ਼嶌ᣱ冑㎿ʣƠ✿儴槹吤癔ᄺ¨呡␵ഁ⁰噉֥൨眪滐䨂ᡂ⣐ก↨ࠇᢼ䥆஧憨㉅ൡ愈س੡じⸯ࿤ৼᨠଇ瀥އ੡䛩墥༴刳䔕ವ傠̀  "
   },
   "outputs": [],
   "source": [
    "PR.PersistTable(df_task_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8077ca66-42b0-46d3-9ea0-eee9c70165b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>Place</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>Weak Layer</th>\n",
       "      <th>Depth_inches</th>\n",
       "      <th>Width_inches</th>\n",
       "      <th>Vertical_inches</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Elevation_feet</th>\n",
       "      <th>__annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Sunset Peak</td>\n",
       "      <td>Snowboarder</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>14.0</td>\n",
       "      <td>960</td>\n",
       "      <td>360.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>No Annotation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Patsy Marly</td>\n",
       "      <td>Skier</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>North</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>No Annotation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Two Dogs</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Facets</td>\n",
       "      <td>36.0</td>\n",
       "      <td>840</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>No Annotation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Emma Ridges</td>\n",
       "      <td>Skier</td>\n",
       "      <td>New Snow</td>\n",
       "      <td>18.0</td>\n",
       "      <td>600</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>No Annotation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Sunset Peak</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Facets</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18000</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>No Annotation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Region        Place      Trigger  \\\n",
       "0 2012-11-09  Salt Lake  Sunset Peak  Snowboarder   \n",
       "1 2012-11-11  Salt Lake  Patsy Marly        Skier   \n",
       "2 2012-11-11  Salt Lake     Two Dogs        Skier   \n",
       "3 2012-11-11  Salt Lake  Emma Ridges        Skier   \n",
       "4 2012-11-11  Salt Lake  Sunset Peak        Skier   \n",
       "\n",
       "                    Weak Layer  Depth_inches  Width_inches  Vertical_inches  \\\n",
       "0  New Snow/Old Snow Interface          14.0           960            360.0   \n",
       "1  New Snow/Old Snow Interface          30.0          1200           1200.0   \n",
       "2                       Facets          36.0           840           5400.0   \n",
       "3                     New Snow          18.0           600           6000.0   \n",
       "4                       Facets          42.0         18000           9600.0   \n",
       "\n",
       "      Aspect  Elevation_feet  __annotations  \n",
       "0      North         10400.0  No Annotation  \n",
       "1      North          9700.0  No Annotation  \n",
       "2      North         10200.0  No Annotation  \n",
       "3  Southeast         10200.0  No Annotation  \n",
       "4      North         10400.0  No Annotation  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task_1c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ed0a8-dc0b-4ac8-8afd-b554ea8f4d28",
   "metadata": {},
   "source": [
    "# Task 2: Filtering data\n",
    "\n",
    "In Task 2, we further improve our data by removing outliers and removing certain records to have more consistent data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25d8f5-98e8-4b0f-9358-ed85f77cbed8",
   "metadata": {},
   "source": [
    "## **Task 2a: Remove Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53a605-2d10-4457-9625-70ce88f04f3b",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this task, we address data accuracy by filtering out anomalies in elevation data. We observe some records with elevations outside the plausible range for Utah, suggesting recording errors.\n",
    "\n",
    "Remove avalanche records with elevations below 2000 feet and above 13500 feet, which are outside the realistic range for Utah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c641e-1193-4233-8897-0161f209c86f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Identify and Remove Anomalies:**\n",
    "    - Interactively select data points with elevations below 2100 feet and above 13500 feet in the Persist Scatterplot.\n",
    "    - Use Persist's interactive features to remove these anomalous records.\n",
    "2. **Generate Dataframe:**\n",
    "    - Assign the cleaned dataframe to a variable `df_task_2a`.\n",
    "3. **Show Output:**\n",
    "    - Display the head of `df_task_2a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5727a-f059-4bf3-977c-1ce0d6d92eba",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.plot.scatterplot(df_task_1c, \"Elevation_feet:Q\", \"Vertical_inches:Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447b862-90c6-4ed7-b48b-baa1cf74ac2d",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰࣠✴ƀචآ൐ୠᣠ⭎¸䚀ᶥ<⋵攴≲䦆ᨐ҅䁲䥈kᑄᄈ夒ર囇⣹嗛➎帣ᢤ䀡傠Ǘ熠㥀ॢȠா䠸ᢀ㜰䁾巒•橀樠Ꮃ䤠ව׷核ᱬ䣘紲₞૦Ԡ޳ŀ凐栠晬╍ಲ䖽䂇栢沀團ᄰ㸸ሪ喊Ⴇ♁䐔粶ᦞΎ刺ࠥ簉窺簲ᖢොሧ҉䃵ⰡḠޅ毗䘤䗾墥୚渍磆搰㣄䆯䌭䊣ᎄ䢩妈䪑䴹ҩ䋫◂რ⢒ઉ⃁⽌囦媍ኘ垤䢠䍤⒂Йᘷ੡䄀҂Ქ⃱琿啡憐㲞ၯ䌨焠ᗿ搫໎㒫ல熪Ņ⎃ऺᥛ⃄ᅠ  "
   },
   "source": [
    "## **Task 2b: Filtering Out Old Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b30d4-4762-4bc0-bfd3-6f1486b55ad6",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰࣠✴ƀචآ൐ୠᣠ⭎¸䚀ᶥ<⋵攴≲䦆ᨐ҅䁲䥈kᑄᄈ夒ર囇⣹嗛➎帣ᢤ䀡傠Ǘ熠㥀ॢȠா䠸ᢀ㜰䁾巒•橀樠Ꮃ䤠ව׷核ᱬ䣘紲₞૦Ԡ޳ŀ凐栠晬╍ಲ䖽䂇栢沀團ᄰ㸸ሪ喊Ⴇ♁䐔粶ᦞΎ刺ࠥ簉窺簲ᖢොሧ҉䃵ⰡḠޅ毗䘤䗾墥୚渍磆搰㣄䆯䌭䊣ᎄ䢩妈䪑䴹ҩ䋫◂რ⢒ઉ⃁⽌囦媍ኘ垤䢠䍤⒂Йᘷ੡䄀҂Ქ⃱琿啡憐㲞ၯ䌨焠ᗿ搫໎㒫ல熪Ņ⎃ऺᥛ⃄ᅠ  "
   },
   "source": [
    "The interactive barchart below, shows the data aggregated by year. There are noticeably fewer records for the years before 2010.\n",
    "\n",
    "During this subtask we will remove the older records, keeping only the records post 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b308e8-8437-4146-9ebf-cd121aeb7f9f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Create and Analyze Bar Chart:**\n",
    "    - Looking at an interactive bar chart in Persist showing the number of avalanches recorded each year, identify the bars showing data we want.\n",
    "2. **Interactive Year Selection:**\n",
    "    - Use a brush to interactively select and remove appropriate records.\n",
    "3. **Generate Dataframe:**\n",
    "    - Assign the refined dataframe to a variable `df_task_2b`.\n",
    "4. **Show Output:**\n",
    "    - Display the head of `df_task_2b` to verify the removal of earlier years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488acb7-e239-4d7e-92ef-3e9d74c3d823",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.plot.barchart(df_task_2a, \"utcyear(Date):O\", \"count()\", selection_type=\"interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fdc8b-168e-40e2-861c-d23095a4a8d8",
   "metadata": {},
   "source": [
    "## **Task 2c: Identifying frequently failing `Weak Layers` for avalanches triggered by _'snowboarders'_ and _'skiers'_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd956e34-f1c9-40d3-8702-a2a84e304ca9",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Linked Bar Charts:**\n",
    "    - You will start with two linked interactive bar charts: one for `Trigger` and another for `Weak Layer`.\n",
    "    - Both bar charts show `count` for their respective category.\n",
    "    - You can click on a trigger in the `Trigger` bar chart and the `Weak Layer`' bar chart dynamically updates to show only occurrences corresponding to the selected triggers.\n",
    "2. **Interactive Selection:**\n",
    "    - Interactively select triggers and use the updated `Weak Layer`.\n",
    "3. **Identify the most frequent failure point:**\n",
    "    - Analyze the filtered 'Weak Layer' bar chart to determine the most frequently failed layers for selected category and make a note in a markdown cell about both the name of the layer and frequency.\n",
    "4. **Generate Dataframe and Output:**\n",
    "    - You will not generate any dataframe for this task. NOTE: Please save the notebook after you are finsihed with interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef4ea0-bf81-42be-a35a-23e56081f77e",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "pts = alt.selection_point(name=\"selector\", fields=['Trigger'])\n",
    "\n",
    "base = alt.Chart(df_task_2b).encode(y=\"count()\")\n",
    "\n",
    "trigger = base.mark_bar().encode(\n",
    "    x=\"Trigger:N\",\n",
    "    color=alt.condition(pts, \"Trigger:N\", alt.value(\"gray\"))\n",
    ").add_params(pts)\n",
    "\n",
    "weak_layer = base.mark_bar().encode(\n",
    "    x=\"Weak Layer:N\",\n",
    "    color=\"Weak Layer:N\",\n",
    "    tooltip=\"count()\"\n",
    ").transform_filter(\n",
    "    pts\n",
    ")\n",
    "\n",
    "chart = alt.hconcat(\n",
    "    trigger, weak_layer\n",
    ").resolve_scale(\n",
    "    color=\"independent\",\n",
    ")\n",
    "\n",
    "PR.PersistChart(chart, data=df_task_2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f44925-7703-4844-98ee-d1280f0b10e5",
   "metadata": {},
   "source": [
    "**Task 2c Notes:**\n",
    "\n",
    "Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92b8a9-c3a8-4a57-be3b-c9cdc977092c",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ⬠沈֭⠸恍ff9昽䁮ۦ࠰汬നڀপ㈏䣹厠㬦ተ¶⡨⇱㌀ᅁ╶庳ୖ⹜簧ଭࠣ℠Έ橦औ䁅ШNႦ〡岁䏼ℭ㞁摞+㢱䨠Ԋ牠Έƕ٦枓቙ჿਸ旑䅠Ȅ恨戬പᎭె䝁净儬Ö᡻⌸䐱䘩׍宨⇓ࡱ䍲ච᫲壬จ䙤Ɲڣ圖⍞ᛡ৽ण䃔戋㘠传ϊ揿振䘌汣䓼㹮䘫㈨ቺ⩯↧ᄨXഉ⠅ㅖࢢ侸⇄僡ಖࡢҁ氣С宍劄倶䢡⍤㲂̤㚗٩䄀硂಩⍰琦ᦪ悑屾ᾨႨ㺜*瘪䋇޶⋤ᓘ犠䭳঺᥇⏰ᅠ  "
   },
   "source": [
    "## Task 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da80393-7f4b-4115-a4d1-5b7978e11358",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "### Task 3a: Creating and assigning 'Avalanche Season'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402412ae-3b84-4fec-9c01-94dd203a7b1f",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "#### **Objective**\n",
    "\n",
    "In this subtask, we'll introduce a new categorical variable named `Avalanche Season` into our dataset. This addition aims to classify each avalanche record into different parts of the avalanche season (Start, Middle, End) based on the month it occurred.\n",
    "\n",
    "Create a new category `Avalanche Season` in the dataset and assign each record to `Start`, `Middle`, or `End` of the avalanche season based on its month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d54d80-ef52-4630-bffb-1e04d9320384",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Visualization**\n",
    "    - We will work with an interactive bar chart in Persist showing the count of avalanche instances aggregated by month.\n",
    "2. **Define Season Categories:**\n",
    "    - Based on typical avalanche seasons in Utah, you will first create a new category called `Avalanche Season` using the `Edit Categories` button in the header.\n",
    "    - In the same menu you will add three options for this category -- `Start`, `Middle`, `End`.\n",
    "3. **Interactive Assignment:**\n",
    "    - Use Persist's interactive features to select each month and assign it to one of the `Avalanche Season` values (Start, Middle, End).\n",
    "    - You should use the following ranges for assigning proper categories:\n",
    "        - `Start` of Season: October, November, December, January, February\n",
    "    \t- `Middle` of Season: March, April, May,\n",
    "    \t- `End` of Season: June, July, August, September\n",
    "4. **Generate Dataframe:**\n",
    "    - Assign the updated dataset to a new variable: `df_task_3a`.\n",
    "5. **Show Output:**\n",
    "    - Print the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b62f4c-8841-4f6c-8011-cb2ee31c2c7b",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "select = alt.selection_interval(name=\"selector\", encodings=[\"x\"])\n",
    "\n",
    "chart = alt.Chart(df_task_2b, height=400, width=500).mark_bar().encode(\n",
    "    x=alt.X(\"utcmonth(Date):N\"),\n",
    "    y=\"count()\",\n",
    "    opacity=alt.condition(select, alt.value(1), alt.value(0.2))\n",
    ").add_params(select)\n",
    "\n",
    "PR.PersistChart(chart, data=df_task_2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e82a42-5f2f-44e1-b9a5-2e2d403b2ff3",
   "metadata": {},
   "source": [
    "# **Task 3b: Analyzing Top Avalanche Trigger by Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40bad3-436e-426c-a02f-f205597e90b5",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this subtask, we'll analyze which trigger is most prevalent for avalanches in each season phase (Start, Middle, End) using the `Avalanche Season` category created in Task 3a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72455a32-623b-4b87-87d6-ca9c8ebf19e7",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Visualization:**\n",
    "    - We have two linked interactive bar charts: one for 'Avalanche Season' and another for 'Trigger'.\n",
    "    - You can select a category to highlight using the **legend** for `Avalanche Season` bar chart. The `Trigger` bar chart will dynamically update in response to your selections.\n",
    "2. **Analyze Trigger Data:**\n",
    "    - Observe the filtered `Trigger` bar chart to identify the top trigger for the selected season phase.\n",
    "    - You can hover on the bars to get the exact frequency.\n",
    "3. **Document Findings:**\n",
    "    - Note down the most common trigger for each season phase based on your interactive analysis in a new markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eaff25-74aa-4e43-abbb-19bdfef91064",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "selection = alt.selection_point(name=\"selector\", fields=[\"Avalanche Season\"], bind=\"legend\")\n",
    "base = alt.Chart(df_task_3a)\n",
    "\n",
    "seasons = base.mark_bar().encode(\n",
    "    x=alt.X(\"Avalanche Season:N\").sort([\"Start\", \"Middle\", \"End\"]),\n",
    "    y=\"count()\",\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.3)),\n",
    "    color=\"Avalanche Season:N\"\n",
    ").add_params(\n",
    "    selection\n",
    ")\n",
    "\n",
    "trigger = base.mark_bar().encode(\n",
    "    x=\"Trigger:N\",\n",
    "    y=\"count()\",\n",
    "    color=\"Trigger:N\",\n",
    "    tooltip=\"count()\"\n",
    ").transform_filter(\n",
    "    selection\n",
    ")\n",
    "\n",
    "chart = seasons | trigger\n",
    "\n",
    "chart = chart.resolve_scale(\n",
    "    color=\"independent\"\n",
    ")\n",
    "\n",
    "PR.PersistChart(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e87acd-3759-49eb-9e43-d7793672297c",
   "metadata": {},
   "source": [
    "**Task 3b Notes:**\n",
    "\n",
    "Write your answer here"
   ]
  }
 ],
 "metadata": {
  "__CATEGORIES_META__": "{\"categories\":{\"Avlanche Season Phase\":{\"name\":\"Avlanche Season Phase\",\"options\":{\"_None\":{\"name\":\"None\"},\"Start\":{\"name\":\"Start\"},\"Middle\":{\"name\":\"Middle\"},\"End\":{\"name\":\"End\"}}}},\"activeCategoryName\":\"Avlanche Season Phase\"}",
  "__persist_keys_record": [
   "__GENERATED_DATAFRAMES__",
   "__persist_nb_uuid__",
   "trrack_graph",
   "show_aggregate_origin"
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
