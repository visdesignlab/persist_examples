{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "917cab9a-0a56-450c-b0b3-1bdf90816f21",
   "metadata": {},
   "source": [
    "# Demo for Persist Jupyter Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253cc5c-b3e8-4102-802a-cbc1f91b3aae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### You can follow the tutorial at the following URL:\n",
    "\n",
    "\n",
    "<a href=\"https://tinyurl.com/44euyhtw\" style=\"font-size: 2em\"><code>https://tinyurl.com/44euyhtw</code></a>\n",
    "\n",
    "<img src=\"thesis_demo_qr.png\" alt=\"QR Code for https://tinyurl.com/44euyhtw\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960be18-804d-4e84-a6a7-b5ed33d22b52",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "If you are following along"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fcbb3-702c-4ea0-91d9-f3b0e71690fc",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰àᦴ΀࣪ʐ怶䦠挠᱊ࠥ䁁䂖㚥煤晬փ⊪ĸ暂䙠঳ैkᑄᄈ妐ଷᓋ⃩䖻Ṯ溜Φ䐡傠Ǒ団Қ′䈤7ࡣᠠ湐戎Ⴆ寐爤䀥屨攠ʕ㥀ǔÚ䍃㏙䤥ࢂ┩勸惀Ēいཆ༠೥∁∀秸㲅䌠ⶬᛦ䙂ǃɡ殍戰泤ᒁ嬦怭㋉匥穃ᄠ彣჻⴦䉫ぢ睤䄁ⵐۻG䀡曑砑䂱竖ᄂ㜿Ꭽ˹ȩᚱ凁兘㑐Ṣ༩Ẻ䳥⑆憰棨忞⍧攈堽Ī僰὆揖䦲ᡊ⛓౱নఱ姼ᤦΧ您別൧儸晋Ǣ熘繀䉁硨K塊়ṹᜰ倳䪂ⵦ⚈ᒽ᪺ᆬ䀠 "
   },
   "source": [
    "# Analyzing Utah Avalanche Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac0d48-2820-4532-bfd2-adf6533d7a2d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For this live demo, I will do some basic data cleanup tasks on the avalanche data take from [Utah Avalanche Center](https://utahavalanchecenter.org/). The data provides insights into [avalanche occurrences](https://utahavalanchecenter.org/avalanches) in Utah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9337796b-21e8-4c8c-bbbd-3076a775d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # For saving/loading data\n",
    "import altair as alt # For creating VegaAltair visualizations\n",
    "\n",
    "import persist_ext as PR # Load Persist extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81aecd-eebf-4624-b9e2-3a864c474c1d",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ҁ̡䘠烠嘢త〫‥侴ᓬᛞ拐ৡ䚂ద抭婈ހڅྯ䌲⠠䭈⑁槑焳Ⴥ⩦仃㍶๽㰥Ҩǁ#㟢䌰橠ኤРᜰ͐üメ湁˛㾄ָ̠憴)挄䀦栢琭ٮ㍄ᨡ䌤ᾣㆢ䀣擠䢤㘦Sᥧᡠ戂怡ᠬÖᠻ㹈䐿ة׉妨⃓ࢱ̴㖠᫲徤ฏѤƜڣ回㸦ۡ৵ण䃔戊㘠传ϊ緯挡䘌污䕽庮粓㈨ɪⷠ搃猄ᦨ洘㳌ᤪ̪౦繶ሱ澂䘣⁑Ҝഭ炍孉ृÅ⭱䤾ᢠ䆋෭ኀ㠢Ү≱呺Ấ惑汮ᮯ戩䊏̠˙Ɂ⧽憳㈒ṉⅱਊ⥋⃆瑀⣨  "
   },
   "source": [
    "## Data Description\n",
    "\n",
    "The table below describes the different columns in the dataset. Each row in the dataset represents a reported avalanche with location, trigger, and aspect details. The data spans multiple years, from __2004__ to __2023__.\n",
    "\n",
    "| Column          | Description                                                    |\n",
    "|-----------------|----------------------------------------------------------------|\n",
    "| Date            | Date on which the avalanche was recorded                       |\n",
    "| Region          | Region in Utah where the avalanche occurred                    |\n",
    "| Place           | Exact location where the avalanche was recorded                |\n",
    "| Trigger         | Cause of the avalanche                                         |\n",
    "| Weak Layer      | Layer of snow that was weakest and likely to fail              |\n",
    "| Depth_inches    | Depth of the avalanche in inches                               |\n",
    "| Width_inches    | Width of the avalanche in inches                               |\n",
    "| Vertical_inches | Vertical distance covered by the avalanche in inches           |\n",
    "| Aspect          | Direction of the slope where the avalanche occurred            |\n",
    "| Elevation_feet  | Elevation of the location in feet                              |\n",
    "| Coordinates     | Approximate geographical coordinates of the avalanche location |\n",
    "| Comments 1      | Additional comments provided by the reporter                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e426c-89a0-4813-8994-65ebba3f3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./avalanches_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1094a-e8ac-4bdc-bc73-efc0a75d50e2",
   "metadata": {},
   "source": [
    "## Column Manipulation Tasks\n",
    "\n",
    "#### Delete columns `Coordinates` and `Comments 1`\n",
    "#### Remove `;` from `;Region` and `;Trigger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e333ff3-cb24-430b-a332-733b41570ba4",
   "metadata": {
    "__has_persist_output": true,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PR.PersistTable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca08701b-2697-480f-8faf-681ce82a9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563eb8ea-66c6-4c03-9c4c-54ea2eb717e1",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ˣĸѐᦻϐրୣF☡䲩※ਡᱤĀၑ䀦ᆺⵕ暕ᣀɒ㉪2攩кᙼ䉅擊桖㎉淢域ᑡᅀ†浑ӦẰӁĠװ搬W౐ި₏湝〡㜶ᥠ¼湨N䣸持㉧ㄺ奣ᢖᡈ\\䰩ຣ⟆惂䧹夔琴Ī࣠ஃϔ憨䅐悰㫛㢤᭑Դ㈵堣ⳋᣡ㺨摠៨摖棄拑氰己ၘ⭬ǎ怩瀠㧎㸜ヌ㻍䑘己洉䓖₢◄㒜♶ᑚਨ䛤撁∴惘⡰ᑂཊ怰⾚ጥ΀䲌ᇩ复劄䘪䧌挴⊂̥㘯١䄁碂಩⍰瑦֡憐㱞lከ䤠ᗸᔩ亾ⲷࡰ৪ㅍ⍆㓺ᕟ⌹  "
   },
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a5a56-a415-44d4-9be4-4c4e22f68502",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Column Removal:**\n",
    "\t- Remove the specified columns using Pandas commands.\n",
    "2. **Generate dataframe:**\n",
    "\t- Assign the modified dataframe to variable `df_task_1a`\n",
    "3. **Show Output:**\n",
    "\t- Print the head of `df_task_1a` to show the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15449b-4ead-4e30-b779-dd88a7169454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc5ff1-bd9c-44fe-ab9f-454e3341195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1a = df.drop(columns=[\"Comments 1\", \"Coordinates\"])\n",
    "\n",
    "df_task_1a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c62d50-9c88-4ed9-8c97-e552a6e4c620",
   "metadata": {},
   "source": [
    "### **Task 1b: Fix Column Names**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f8f24-afd2-424f-ab34-3e3cde723aa3",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ࢀㆪこ<ǐʀ୥崡汤Ɓ䔠⍂⠨撂䂼ì债晶堪慯掩ᐠ▴ሰ璹㤨䮲减ⓥ䢧᜾㺣䉠ð䀡壅冨㕀ॢȠ௞䠸ᢀ眰䅽忖䀢晐樠Ԃ牠ΈƔڦ❓ሠƠ暬ॡ声Ȅ恨䙜⬮ಬ俨⫣䞐డ㙐᬴⣔䰲ճ㌰䊆၂۔欠㖹┰᧶༨̘ඛฌ琻ɋ㉄ܠ榡哸Ŝ.ؗ⾬ള勑̵㯺ᱱ曨ဩᒡᾪ३⁂惡৒ј⪖ᩋࢶ䥣䍢ᇃ⢀☾ԣ䖎㑝䳓ⳄⓀ᪱ĦҐ戤׌㝔䆦成扉ڠ凈㨣ೣㅘ湏Bࡤ䒠ଈତޗ٩䟨㣜㥨◈ᩲ㭡⟢䀠 "
   },
   "source": [
    "#### **Objective**\n",
    "For this subtask, we will focus on fixing column names to ensure consistency and clarity. We'll start by identifying the issues with the column names, specifically targeting those with a `;` prefix that needs removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedcbe71-9d1d-4e28-a869-cb07b33f8074",
   "metadata": {},
   "source": [
    "#### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4d5c5-9383-4857-beae-0cfa6ba466f2",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Rename Columns:**\n",
    "    - Use the interactive  table in Persist to correct the column names by removing the leading `;` from their names:\n",
    "        - _;Aspect_ → _Aspect_\n",
    "        - _;Region_ → _Region_\n",
    "        - _;Trigger_ → _Trigger_\n",
    "        - _;Weak Layer_ → _Weak Layer_\n",
    "2. **Generate dataframe:**\n",
    "    - Assign the revised dataframe to the variable `df_task_1b`.\n",
    "3. **Show Output:**\n",
    "    - Display the head of `df_task_1b` to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74dd265-2437-40e4-8673-be7ea1d079b3",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.PersistTable(df_task_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43121e-7493-4db0-a00f-3cef59136676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffac29-972f-4c76-9351-2c954854e7a4",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ded8ee-7828-494d-afeb-8f5b5b5595f1",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰à⬠氤瀹䂃¦¸˰ҁ①าÐɐ໦䓊禳Ӧ攆⩧琫樁拄䨠ዪन㪌糥效桖㖎槻域℁兀†沤挹䠤傡%梄ؠᮬᢛ䑁圌ḀÐ乒䀡ᵼ䠠洠⺱壹溄䅢ᨀ䈩㙐⠠㲸ब佄⍦儂ト桦{్䂼∠⌤䉶汄ၹ䑨凝۠ඊ⡂ڗ䉂Þ⍾捠ೠ䞫づ㕤䄀൐櫻G䀡擑琑䈂㫶ဲ㜧Ꭱ˹ȥᆲ冲椒咃ᨼᐱᒶ䭢䇡Ᏹユ僌䘼ᚦᩐ挬ദ䌜๵䎃ᅄ〴䦈᥃䌰ࡃ㏙㉬ᜨ⊰ᒊ຤惐氮ண成ɁѦቄwၤቘ㲒㙑⏤咤窤䫳䧚ᕄй  "
   },
   "source": [
    "#### **Instructions**\n",
    "1. **Rename Columns:**\n",
    "    - Employ Pandas commands to rename the columns, eliminating the leading \";\" as specified:\n",
    "        - _;Aspect_ → _Aspect_\n",
    "        - _;Region_ → _Region_\n",
    "        - _;Trigger_ → _Trigger_\n",
    "        - _;Weak Layer_ → _Weak Layer_\n",
    "2. **Generate dataframe:**\n",
    "    - Assign the updated dataframe to variable `df_task_1b`.\n",
    "3. **Show Output:**\n",
    "    - Print the head of `df_task_1b` to confirm the updated column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1660a9a4-bbf0-42d9-aacf-ae4c6afa5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8043f-28ef-4f56-95cd-9be8ab0acd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns to remove the leading ';'\n",
    "df_task_1b = df_task_1a.rename(columns={\n",
    "    \";Region\": \"Region\",\n",
    "    \";Trigger\": \"Trigger\",\n",
    "    \";Weak Layer\": \"Weak Layer\",\n",
    "    \";Aspect\": \"Aspect\",\n",
    "})\n",
    "\n",
    "df_task_1b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875e7fc-ec40-4241-aa94-87b31e59944f",
   "metadata": {},
   "source": [
    "## **Task 1c: Correcting Data Type of 'Depth_inches'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7eebda-1b60-4bff-89d3-a5548a601b49",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this task, we will address a data type issue in the `Depth_inches` column of our dataframe. This column is incorrectly formatted as a object (string) due to the presence of the inches symbol `\"`.\n",
    "\n",
    "Remove any inches symbols `\"` from the `Depth_inches` column and convert it to a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bff61-9a8d-4114-97f3-4f6d0cd0e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c433efa-fcb1-4de7-af16-283cc7f2ac86",
   "metadata": {},
   "source": [
    "### **Persist**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23913ac-ea3c-4ca1-8ac3-07d3026ca76e",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ↺΀Ơ瘢ᠢᠫ‵䁇ፉ䐢怣侽振ၑ䶃᪰঵䂆⹉多䪲┠অҤᴶṂ㊵嘊᭓ㄅ毠㒰䣑Tဠ㚉҃೨ɰ䂠̂҆;䘸Ϥၗ眼䋐Ð䬹†于␠㚠ᝨ沂烒⎁൸憈㬸ᐠṬү䓧Ⴠ椓ᣘ⌚ᆠᛦކ䜱ǁ䅀㖖नຂᩈ桫〦塵偢㶱⢠⾱䂅埦䖃塀㪂ₐ暸ᵽ䀳怠煼砤慸㴻ࠩ㯏姭ঌ䄢䣫䧙㱈刱ㄿᬦ䩫⏃㌱楫磤ⰴຣα晼ਫ䎁㺕䮃Ⴤご䖂᥂挰ы゙㈬ܠ₰ᑊІ僑汮ޯ戩䉱៪怡⹁ᡤ甑擸抯॰ᡬᅓ╄璚╄㈠ "
   },
   "source": [
    "#### **Instructions**\n",
    "1. **Identify Entries with Inches Symbol:**\n",
    "    - Use the interactive table in Persist to look for rows with `\"` in `Depth_inches` column\n",
    "2. **Edit and Correct Entries:**\n",
    "    - Edit the cells to remove the inches symbol from these entries. (e.g. `15\"` → `15`) \n",
    "3. **Convert Data Type:**\n",
    "    - Change the data type of the `Depth_inches` column from string to float.\n",
    "4. **Generate Dataframe:**\n",
    "    - Assign the modified dataframe to a variable `df_task_1c`.\n",
    "5. **Show Output:**\n",
    "    - Display the dtypes of `df_task_1c` to verify the data type correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9b796-3aa5-4181-bf91-fa8ba7e33c20",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.PersistTable(df_task_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e34c89-cbda-490d-9848-318cb7c0594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a007a9-dc27-4c45-aa4d-66ff0074e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bc0d0-5e3f-4b07-bf14-b83f961eb833",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ↺΀Ơ瘢ᠢᠫ‵䁇ፉ䐢怣侽振ၑ䶃᪰঵䂆⹉多䪲┠অҤᴶṂ㊵嘊᭓ㄅ毠㒰䣑Tဠ㚉҃೨ɰ䂠̂҆;䘸Ϥၗ眼䋐Ð䬹†于␠㚠ᝨ沂烒⎁൸憈㬸ᐠṬү䓧Ⴠ椓ᣘ⌚ᆠᛦކ䜱ǁ䅀㖖नຂᩈ桫〦塵偢㶱⢠⾱䂅埦䖃塀㪂ₐ暸ᵽ䀳怠煼砤慸㴻ࠩ㯏姭ঌ䄢䣫䧙㱈刱ㄿᬦ䩫⏃㌱楫磤ⰴຣα晼ਫ䎁㺕䮃Ⴤご䖂᥂挰ы゙㈬ܠ₰ᑊІ僑汮ޯ戩䉱៪怡⹁ᡤ甑擸抯॰ᡬᅓ╄璚╄㈠ "
   },
   "source": [
    "### **Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843f33c-83c6-4d44-a986-820ff11585dc",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ↺΀Ơ瘢ᠢᠫ‵䁇ፉ䐢怣侽振ၑ䶃᪰঵䂆⹉多䪲┠অҤᴶṂ㊵嘊᭓ㄅ毠㒰䣑Tဠ㚉҃೨ɰ䂠̂҆;䘸Ϥၗ眼䋐Ð䬹†于␠㚠ᝨ沂烒⎁൸憈㬸ᐠṬү䓧Ⴠ椓ᣘ⌚ᆠᛦކ䜱ǁ䅀㖖नຂᩈ桫〦塵偢㶱⢠⾱䂅埦䖃塀㪂ₐ暸ᵽ䀳怠煼砤慸㴻ࠩ㯏姭ঌ䄢䣫䧙㱈刱ㄿᬦ䩫⏃㌱楫磤ⰴຣα晼ਫ䎁㺕䮃Ⴤご䖂᥂挰ы゙㈬ܠ₰ᑊІ僑汮ޯ戩䉱៪怡⹁ᡤ甑擸抯॰ᡬᅓ╄璚╄㈠ "
   },
   "source": [
    "#### **Instructions**\n",
    "\n",
    "1. **Remove Inches Symbol and Correct Format:**\n",
    "    - Use Pandas to replace the inches symbol in the `Depth_inches` column.\n",
    "2. **Convert Data Type:**\n",
    "    - Convert the `Depth_inches` column to float.\n",
    "3. **Generate Dataframe:**\n",
    "    - Save the updated dataframe as `df_task_1c`.\n",
    "4. **Show Output:**\n",
    "    - Print the dtypes of `df_task_1c` to confirm the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420d86a-7cff-49d8-a92f-6c6fda61e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d388cb-f5cb-4337-b943-24f8e7a75d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c = df_task_1b\n",
    "df_task_1c[\"Depth_inches\"] = df_task_1c[\"Depth_inches\"].str.replace('\"', '')\n",
    "df_task_1c[\"Depth_inches\"] = df_task_1c[\"Depth_inches\"].astype(\"Float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dee6f-706e-4756-b960-2d061436078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ed0a8-dc0b-4ac8-8afd-b554ea8f4d28",
   "metadata": {},
   "source": [
    "# Task 2: Filtering data\n",
    "\n",
    "In Task 2, we further improve our data by removing outliers and removing certain records to have more consistent data. \n",
    "\n",
    "We will also take a brief look at relations between cause of an avalanche (`Trigger`) and failure point of ice (`Weak Layer`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25d8f5-98e8-4b0f-9358-ed85f77cbed8",
   "metadata": {},
   "source": [
    "## **Task 2a: Remove Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53a605-2d10-4457-9625-70ce88f04f3b",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this task, we address data accuracy by filtering out anomalies in elevation data. We observe some records with elevations outside the plausible range for Utah, suggesting recording errors.\n",
    "\n",
    "Remove avalanche records with elevations below 2000 feet and above 13500 feet, which are outside the realistic range for Utah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad44c7-ecd6-4ca9-9f68-0a8d28d0cb48",
   "metadata": {},
   "source": [
    "#### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c641e-1193-4233-8897-0161f209c86f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Identify and Remove Anomalies:**\n",
    "    - Interactively select data points with elevations below 2100 feet and above 13500 feet in the Persist Scatterplot.\n",
    "    - Use Persist's interactive features to remove these anomalous records.\n",
    "2. **Generate Dataframe:**\n",
    "    - Assign the cleaned dataframe to a variable `df_task_2a`.\n",
    "3. **Show Output:**\n",
    "    - Display the head of `df_task_2a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5727a-f059-4bf3-977c-1ce0d6d92eba",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.plot.scatterplot(df_task_1c, \"Elevation_feet:Q\", \"Vertical_inches:Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959c1a5-bb43-4c3f-ba26-b20957855f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd0373e-79d1-44c0-b8bd-2002afe6684a",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3529a-641b-42b1-9e4d-d51461be760f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Locate Anomalous Data:**\n",
    "    - Refer to the _seaborn_ scatterplot for `Elevation_feet` vs `Vertical_inches`\n",
    "    - Write code to identify records where `Elevation_feet` is either below 2100 feet or above 13500 feet.\n",
    "3. **Remove Anomalies:**\n",
    "    - Use Pandas commands to filter out these anomalous records from the dataframe.\n",
    "4. **Generate Dataframe:**\n",
    "    - Save the cleaned dataframe as `df_task_2a`.\n",
    "5. **Plot Output:**\n",
    "    - Recreate the scatterplot from step 1 in a new cell using `df_task_2a`.\n",
    "    - Print the head of `df_task_2a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e541870-4719-4bd7-bb67-75270450e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2a = df_task_1c\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(data=df_task_2a, x='Elevation_feet', y='Vertical_inches')\n",
    "\n",
    "plt.xlabel('Elevation (feet)')\n",
    "plt.ylabel('Vertical Distance (inches)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754d690-635e-4f21-b6f8-ddc0ab51b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2a = df_task_1c[(df_task_1c['Elevation_feet'] >= 2100) & (df_task_1c['Elevation_feet'] <= 13500)]\n",
    "df_task_2a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3fb23c-ad31-43c1-91ea-fb8952b23ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(data=df_task_2a, x='Elevation_feet', y='Vertical_inches')\n",
    "\n",
    "plt.xlabel('Elevation (feet)')\n",
    "plt.ylabel('Vertical Distance (inches)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447b862-90c6-4ed7-b48b-baa1cf74ac2d",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰࣠✴ƀචآ൐ୠᣠ⭎¸䚀ᶥ<⋵攴≲䦆ᨐ҅䁲䥈kᑄᄈ夒ર囇⣹嗛➎帣ᢤ䀡傠Ǘ熠㥀ॢȠா䠸ᢀ㜰䁾巒•橀樠Ꮃ䤠ව׷核ᱬ䣘紲₞૦Ԡ޳ŀ凐栠晬╍ಲ䖽䂇栢沀團ᄰ㸸ሪ喊Ⴇ♁䐔粶ᦞΎ刺ࠥ簉窺簲ᖢොሧ҉䃵ⰡḠޅ毗䘤䗾墥୚渍磆搰㣄䆯䌭䊣ᎄ䢩妈䪑䴹ҩ䋫◂რ⢒ઉ⃁⽌囦媍ኘ垤䢠䍤⒂Йᘷ੡䄀҂Ქ⃱琿啡憐㲞ၯ䌨焠ᗿ搫໎㒫ல熪Ņ⎃ऺᥛ⃄ᅠ  "
   },
   "source": [
    "## **Task 2b: Filtering Out Old Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b30d4-4762-4bc0-bfd3-6f1486b55ad6",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰࣠✴ƀචآ൐ୠᣠ⭎¸䚀ᶥ<⋵攴≲䦆ᨐ҅䁲䥈kᑄᄈ夒ર囇⣹嗛➎帣ᢤ䀡傠Ǘ熠㥀ॢȠா䠸ᢀ㜰䁾巒•橀樠Ꮃ䤠ව׷核ᱬ䣘紲₞૦Ԡ޳ŀ凐栠晬╍ಲ䖽䂇栢沀團ᄰ㸸ሪ喊Ⴇ♁䐔粶ᦞΎ刺ࠥ簉窺簲ᖢොሧ҉䃵ⰡḠޅ毗䘤䗾墥୚渍磆搰㣄䆯䌭䊣ᎄ䢩妈䪑䴹ҩ䋫◂რ⢒ઉ⃁⽌囦媍ኘ垤䢠䍤⒂Йᘷ੡䄀҂Ქ⃱琿啡憐㲞ၯ䌨焠ᗿ搫໎㒫ல熪Ņ⎃ऺᥛ⃄ᅠ  "
   },
   "source": [
    "The interactive barchart below, shows the data aggregated by year. There are noticeably fewer records for the years before 2010.\n",
    "\n",
    "During this subtask we will remove the older records, keeping only the records post 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf19e6-3600-4f27-b587-885ba7443360",
   "metadata": {},
   "source": [
    "### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b308e8-8437-4146-9ebf-cd121aeb7f9f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Create and Analyze Bar Chart:**\n",
    "    - Looking at an interactive bar chart in Persist showing the number of avalanches recorded each year, identify the bars showing data we want.\n",
    "2. **Interactive Year Selection:**\n",
    "    - Use a brush to interactively select and remove appropriate records.\n",
    "3. **Generate Dataframe:**\n",
    "    - Assign the refined dataframe to a variable `df_task_2b`.\n",
    "4. **Show Output:**\n",
    "    - Display the head of `df_task_2b` to verify the removal of earlier years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488acb7-e239-4d7e-92ef-3e9d74c3d823",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.plot.barchart(df_task_2a, \"utcyear(Date):O\", \"count()\", selection_type=\"interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3f8a6-09fb-4338-ad2b-af9ecc1b2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc78231-4b97-4d4d-82ee-2a762d20e590",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ǡ⬪兠䘤瀥䁍ᴡْ࿪Č⬭总ҡ䲤䫳⩨࣪恆ᖜæⓀŌ傰䏄懠Ɑಥ㕺۬汙㬐਺ဦ䈠ۤ嬬ሉj࠰|ℬ怣㣣ߘ䈺滣䢁6煃ᐠ৵撠۰̊ಭ伆⑶⇐呄䮃ʠϩ䂰㴔屆㹟Ե䏯柧慲డ㙐嬲ᢨҬध⷗ࡣ㌰冦氻U䫄䰷梬䐢紬䎍Sॐ囡׽ण䋔总㘠传Ϛ揿挬ᐎ汣䓼㹮ራ㈨ቺ╯慂厃૵ⴘ嘪⭓炻ࡿ⑁℘ⸯţ✘௨∑㛛㒹ᆢ匋᣹ࢸ䃡ල憰へḨ䕃䢴മ䒀夌✻䐂тྸ•嶢僙戅䢑՞ዂᏴ剶䅭槉ㆰ  "
   },
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb76fc-6ea4-4296-8c50-39381f09d9c8",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Create Bar Chart with Seaborn:**\n",
    "    - Use the Seaborn plot with bar chart visualizing the number of avalanches per year. \n",
    "2. **Identify Sparse Years:**\n",
    "    - Based on the bar chart, identify years before 2010 with fewer avalanche records.\n",
    "3. **Code to Filter Out Sparse Years:**\n",
    "    - Write Pandas code to exclude these years from the dataset.\n",
    "4. **Show Output:**\n",
    "    - Print the head of `df_task_2b` and optionally recreate the bar chart to show the dataset focusing on years 2010 and onwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1769eaa-8327-4aba-86cb-887cb4b669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b = df_task_2a\n",
    "df_task_2b = df_task_2b.convert_dtypes()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=df_task_2b[\"Date\"].dt.year)\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('# of records')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a2dc3-1542-407e-a6ad-a090ecfa306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b = df_task_2b[df_task_2b[\"Date\"].dt.year >= 2010]\n",
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de087e1d-793f-41f6-ba01-0809d0833fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=df_task_2b[\"Date\"].dt.year)\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('# of records')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e94f0f-6d40-4144-a112-7898433fd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fdc8b-168e-40e2-861c-d23095a4a8d8",
   "metadata": {},
   "source": [
    "## **Task 2c: Identifying frequently failing `Weak Layers` for avalanches triggered by _'snowboarders'_ and _'skiers'_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950defa-280e-4ec5-b59d-c3cd7e2ebcbe",
   "metadata": {},
   "source": [
    "### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd956e34-f1c9-40d3-8702-a2a84e304ca9",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Linked Bar Charts:**\n",
    "    - You will start with two linked interactive bar charts: one for `Trigger` and another for `Weak Layer`.\n",
    "    - Both bar charts show `count` for their respective category.\n",
    "    - You can click on a trigger in the `Trigger` bar chart and the `Weak Layer`' bar chart dynamically updates to show only occurrences corresponding to the selected triggers.\n",
    "2. **Interactive Selection:**\n",
    "    - Interactively select triggers and use the updated `Weak Layer`.\n",
    "3. **Identify the most frequent failure point:**\n",
    "    - Analyze the filtered 'Weak Layer' bar chart to determine the most frequently failed layers for selected category and make a note in a markdown cell about both the name of the layer and frequency.\n",
    "4. **Generate Dataframe and Output:**\n",
    "    - You will not generate any dataframe for this task. NOTE: Please save the notebook after you are finsihed with interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef4ea0-bf81-42be-a35a-23e56081f77e",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "pts = alt.selection_point(name=\"selector\", fields=['Trigger'])\n",
    "\n",
    "base = alt.Chart(df_task_2b).encode(y=\"count()\")\n",
    "\n",
    "trigger = base.mark_bar().encode(\n",
    "    x=\"Trigger:N\",\n",
    "    color=alt.condition(pts, \"Trigger:N\", alt.value(\"gray\"))\n",
    ").add_params(pts)\n",
    "\n",
    "weak_layer = base.mark_bar().encode(\n",
    "    x=\"Weak Layer:N\",\n",
    "    color=\"Weak Layer:N\",\n",
    "    tooltip=\"count()\"\n",
    ").transform_filter(\n",
    "    pts\n",
    ")\n",
    "\n",
    "chart = alt.hconcat(\n",
    "    trigger, weak_layer\n",
    ").resolve_scale(\n",
    "    color=\"independent\",\n",
    ")\n",
    "\n",
    "PR.PersistChart(chart, data=df_task_2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f44925-7703-4844-98ee-d1280f0b10e5",
   "metadata": {},
   "source": [
    "**Task 2c Notes:**\n",
    "\n",
    "- Snowboarder -> New snow/old snow interface (31)\n",
    "- Skiers -> Facets (261)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d12c10-edb7-4c5f-82a9-ca160de89a51",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda516c-ca0c-4ecc-bd48-e40287c4193d",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Identify Predominant Weak Layer:**\n",
    "    - Determine the most common weak layer for these `Snowboarder` and `Skier` triggers for the data.\n",
    "2. **Output:**\n",
    "    - Note in markdown cell both the name of the layer and frequency for each of the above trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7aebd-b709-4b35-80c3-a7c872de6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43696d-904e-4531-9972-551cab614735",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowboarders = df_task_2b[df_task_2b[\"Trigger\"] == \"Snowboarder\"]\n",
    "snowboarders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd93315-4921-4c23-865b-814c02530bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiers = df_task_2b[df_task_2b[\"Trigger\"] == \"Skier\"]\n",
    "skiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11cad5-70a5-47ce-a4a1-86a1d989d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowboarders[\"Weak Layer\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ae661-d569-4f67-b02e-188b2b6f1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiers[\"Weak Layer\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052071fd-2755-4c50-b65b-d4ade860d910",
   "metadata": {},
   "source": [
    "- snowboarders -> New Snow/Old Snow Interface    (31)\n",
    "- skiers -> Facets                         (261)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92b8a9-c3a8-4a57-be3b-c9cdc977092c",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ⬠沈֭⠸恍ff9昽䁮ۦ࠰汬നڀপ㈏䣹厠㬦ተ¶⡨⇱㌀ᅁ╶庳ୖ⹜簧ଭࠣ℠Έ橦औ䁅ШNႦ〡岁䏼ℭ㞁摞+㢱䨠Ԋ牠Έƕ٦枓቙ჿਸ旑䅠Ȅ恨戬പᎭె䝁净儬Ö᡻⌸䐱䘩׍宨⇓ࡱ䍲ච᫲壬จ䙤Ɲڣ圖⍞ᛡ৽ण䃔戋㘠传ϊ揿振䘌汣䓼㹮䘫㈨ቺ⩯↧ᄨXഉ⠅ㅖࢢ侸⇄僡ಖࡢҁ氣С宍劄倶䢡⍤㲂̤㚗٩䄀硂಩⍰琦ᦪ悑屾ᾨႨ㺜*瘪䋇޶⋤ᓘ犠䭳঺᥇⏰ᅠ  "
   },
   "source": [
    "## Task 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da80393-7f4b-4115-a4d1-5b7978e11358",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "### Task 3a: Creating and assigning 'Avalanche Season'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402412ae-3b84-4fec-9c01-94dd203a7b1f",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "#### **Objective**\n",
    "\n",
    "In this subtask, we'll introduce a new categorical variable named `Avalanche Season` into our dataset. This addition aims to classify each avalanche record into different parts of the avalanche season (Start, Middle, End) based on the month it occurred.\n",
    "\n",
    "Create a new category `Avalanche Season` in the dataset and assign each record to `Start`, `Middle`, or `End` of the avalanche season based on its month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10e24c-fa9a-40cf-9246-98d9c20d920b",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d54d80-ef52-4630-bffb-1e04d9320384",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Visualization**\n",
    "    - We will work with an interactive bar chart in Persist showing the count of avalanche instances aggregated by month.\n",
    "2. **Define Season Categories:**\n",
    "    - Based on typical avalanche seasons in Utah, you will first create a new category called `Avalanche Season` using the `Edit Categories` button in the header.\n",
    "    - In the same menu you will add three options for this category -- `Start`, `Middle`, `End`.\n",
    "3. **Interactive Assignment:**\n",
    "    - Use Persist's interactive features to select each month and assign it to one of the `Avalanche Season` values (Start, Middle, End).\n",
    "    - You should use the following ranges for assigning proper categories:\n",
    "        - `Start` of Season: October, November, December\n",
    "    \t- `Middle` of Season: January, February, March\n",
    "    \t- `End` of Season: April, May, June\n",
    "4. **Generate Dataframe:**\n",
    "    - Assign the updated dataset to a new variable: `df_task_3a`.\n",
    "5. **Show Output:**\n",
    "    - Print the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241dba24-94f0-4e16-8fed-be907c66544e",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "select = alt.selection_interval(name=\"selector\", encodings=[\"x\"])\n",
    "\n",
    "chart = alt.Chart(df_task_2b, height=400, width=500).mark_bar(tooltip=True).encode(\n",
    "    x=alt.X(\"utcmonth(Date):N\").sort([10]),\n",
    "    y=\"count()\",\n",
    "    opacity=alt.condition(select, alt.value(1), alt.value(0.2)),\n",
    ").add_params(select)\n",
    "\n",
    "PR.PersistChart(chart, data=df_task_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6696c-ea44-412a-95b7-a979e693d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_df_10[\"M\"] = persist_df_10[\"Date\"].dt.month\n",
    "persist_df_10.groupby(\"M\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceea44e-38de-4938-842d-35cefe3fdc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cef39d-fdc8-4865-bcbc-4702e2bfb8db",
   "metadata": {},
   "source": [
    "### **Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48aaa8-7017-43de-8bd8-190ed9fe4dbd",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Create New Variable:**\n",
    "    - Add a new column `Avalanche Season` to the DataFrame.\n",
    "2. **Assign Category:**\n",
    "    - Using the `month` from the `Date` column assign proper values to the new category.\n",
    "    - You should use the following ranges for assigning proper categories:\n",
    "        - `Start` of Season: October, November, December, January, February\n",
    "    \t- `Middle` of Season: March, April, May,\n",
    "    \t- `End` of Season: June, July, August, September\n",
    "3. **Generate Dataframe:**\n",
    "    - Save the modified DataFrame with the new `Avalanche Season` category to `df_task_3a`.\n",
    "4. **Show Output:**\n",
    "    - Display the head of `df_task_3a` to confirm the addition and categorization of the new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ccdd7-fccd-44ff-b677-7146cef043c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a = df_task_2b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134214fa-bbe0-4502-b4d8-3498139a2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a[\"Avalanche Season\"] = \"End\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd01c0-9371-4e1d-8809-91dce6c1f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b79dff-5762-4159-9d5a-40f498204e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a.loc[df_task_3a[\"Date\"].dt.month.isin([10,11,12,1,2]), \"Avalanche Season\"] = \"Start\"\n",
    "df_task_3a.loc[df_task_3a[\"Date\"].dt.month.isin([3,4,5]), \"Avalanche Season\"] = \"Middle\"\n",
    "\n",
    "df_task_3a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e82a42-5f2f-44e1-b9a5-2e2d403b2ff3",
   "metadata": {},
   "source": [
    "# **Task 3b:## **Analyzing Top Avalanche Trigger by Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40bad3-436e-426c-a02f-f205597e90b5",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this subtask, we'll analyze which trigger is most prevalent for avalanches in each season phase (Start, Middle, End) using the `Avalanche Season` category created in Task 3a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bd750-fbc4-4d0e-aff4-b2d27be38f20",
   "metadata": {},
   "source": [
    "### **Persist**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72455a32-623b-4b87-87d6-ca9c8ebf19e7",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Visualization:**\n",
    "    - We have two linked interactive bar charts: one for 'Avalanche Season' and another for 'Trigger'.\n",
    "    - You can select a category to highlight using the legend for `Avalanche Season` bar chart. The `Trigger` bar chart will dynamically update in response to your selections.\n",
    "2. **Analyze Trigger Data:**\n",
    "    - Observe the filtered `Trigger` bar chart to identify the top trigger for the selected season phase.\n",
    "    - You can hover on the bars to get the exact frequency.\n",
    "3. **Document Findings:**\n",
    "    - Note down the most common trigger for each season phase based on your interactive analysis in a new markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb8ec6-d39a-402a-a4b2-e0c693e5374c",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "selection = alt.selection_point(name=\"selector\", fields=[\"Avalanche Season\"], bind=\"legend\")\n",
    "base = alt.Chart(df_task_3a)\n",
    "\n",
    "seasons = base.mark_bar().encode(\n",
    "    x=alt.X(\"Avalanche Season:N\").sort([\"Start\", \"Middle\", \"End\"]),\n",
    "    y=\"count()\",\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.3)),\n",
    "    color=\"Avalanche Season:N\"\n",
    ").add_params(\n",
    "    selection\n",
    ")\n",
    "\n",
    "trigger = base.mark_bar().encode(\n",
    "    x=\"Trigger:N\",\n",
    "    y=\"count()\",\n",
    "    color=\"Trigger:N\",\n",
    "    tooltip=\"count()\"\n",
    ").transform_filter(\n",
    "    selection\n",
    ")\n",
    "\n",
    "chart = seasons | trigger\n",
    "\n",
    "chart = chart.resolve_scale(\n",
    "    color=\"independent\"\n",
    ")\n",
    "\n",
    "\n",
    "PR.PersistChart(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0981e9f-4fb3-49a4-a62e-b4aeeeb70c8b",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "c = alt.Chart(df_task_3a).mark_bar().encode(\n",
    "    x=\"Trigger:N\",\n",
    "    y=\"count()\",\n",
    "    color=alt.Color(\"Avalanche Season:N\").sort([\"Start\", \"Middle\", \"End\"]),\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.3)),\n",
    "    order=\"selection_order:N\",\n",
    "    tooltip=\"count()\"\n",
    ").transform_calculate(\n",
    "    selection_order=\"if(selector && selector['Avalanche Season'], if((datum['Avalanche Season'] === selector['Avalanche Season'][0]),0,1),0)\"\n",
    ").add_params(selection)\n",
    "\n",
    "\n",
    "PR.PersistChart(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e87acd-3759-49eb-9e43-d7793672297c",
   "metadata": {},
   "source": [
    "**Task 3b Notes:**\n",
    "\n",
    "- Start of season -> Skiers (591)\n",
    "- Middle of season -> Natural (260)\n",
    "- End of season -> Skiers (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9687e-d233-4c64-ae1c-d6d8e2b3e564",
   "metadata": {},
   "source": [
    "### **Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de570e5-ab49-4e8f-b2b1-86b9a2701ece",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Analyze Triggers by Season:*\n",
    "\t- Determine the most common trigger for each season.\n",
    "2. **Present Findings:**\n",
    "\t- Note in markdown cell both the name and frequency for each trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967e8a0-84b9-4723-ab6f-c1660c7a46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_size_df = df_task_3a[[\"Avalanche Season\", \"Trigger\", \"Date\"]].groupby([\"Avalanche Season\", \"Trigger\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "grouped_size_df.sort_values([\"Avalanche Season\", \"counts\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a13e2-c66f-45e6-ba89-2ad0c69afa58",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- End ->\tSkier\t(2)\n",
    "- Middle ->\tNatural\t(260)\n",
    "- Start ->\tSkier\t(591)"
   ]
  }
 ],
 "metadata": {
  "__CATEGORIES_META__": "{\"categories\":{\"Avlanche Season Phase\":{\"name\":\"Avlanche Season Phase\",\"options\":{\"_None\":{\"name\":\"None\"},\"Start\":{\"name\":\"Start\"},\"Middle\":{\"name\":\"Middle\"},\"End\":{\"name\":\"End\"}}}},\"activeCategoryName\":\"Avlanche Season Phase\"}",
  "__persist_keys_record": [
   "__GENERATED_DATAFRAMES__",
   "__persist_nb_uuid__",
   "trrack_graph",
   "show_aggregate_origin"
  ],
  "__persist_nb_uuid__": "1dcde4b3-6e1c-4648-be34-e84246380eb8",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
